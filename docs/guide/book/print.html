<!DOCTYPE HTML>
<html lang="en" class="rust sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Panopticon Guide</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="A guide to building declarative data pipelines with Panopticon">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "rust";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-743fd2df.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-eb8c475d.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('rust')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Panopticon Guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/your-org/panopticon" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<!--
USER: Please write your introduction here.

Suggested content:
- What is Panopticon?
- Why use declarative data pipelines?
- Who is this guide for?
- How to navigate this documentation
-->
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>This guide will walk us through installing Panopticon and running our first data pipeline. By the end, we will understand the basic pattern for building pipelines and be ready to explore more advanced features.</p>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>Add <code>panopticon-core</code> to your project’s <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[dependencies]
panopticon-core = "0.2"
tokio = { version = "1", features = ["macros", "rt-multi-thread"] }
anyhow = "1"
</code></pre>
<p>Panopticon uses <a href="https://tokio.rs/">Tokio</a> for async runtime and <a href="https://docs.rs/anyhow">anyhow</a> for error handling. These are required dependencies for running pipelines.</p>
<h2 id="hello-pipeline"><a class="header" href="#hello-pipeline">Hello Pipeline</a></h2>
<p>Let us build a minimal pipeline that loads a CSV file and prints some basic information about it. This demonstrates the core pattern we will use throughout Panopticon.</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    // 1. Create a new pipeline
    let mut pipeline = Pipeline::new();

    // 2. Define file loading attributes
    let file_attrs = ObjectBuilder::new()
        .insert(
            "files",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "products")
                    .insert("file", "/path/to/products.csv")
                    .insert("format", "csv")
                    .build_scalar(),
            ]),
        )
        .build_hashmap();

    // 3. Add a namespace and command to the pipeline
    pipeline
        .add_namespace(NamespaceBuilder::new("data"))
        .await?
        .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
        .await?;

    // 4. Compile and execute
    let completed = pipeline.compile().await?.execute().await?;

    // 5. Access results
    let results = completed.results(ResultSettings::default()).await?;

    println!("Pipeline completed with {} command(s)", results.len());

    Ok(())
}</code></pre>
<p>Let us break down what is happening:</p>
<ol>
<li>
<p><strong>Pipeline::new()</strong> creates a draft pipeline ready to accept namespaces and commands.</p>
</li>
<li>
<p><strong>ObjectBuilder</strong> constructs the attribute map that configures our command. Here we define a file to load with its name, path, and format.</p>
</li>
<li>
<p><strong>add_namespace()</strong> creates a logical grouping, and <strong>add_command()</strong> adds a command to that namespace. The command is identified by <code>namespace.command</code> (e.g., <code>data.load</code>).</p>
</li>
<li>
<p><strong>compile()</strong> validates the pipeline and resolves dependencies. <strong>execute()</strong> runs all commands in the correct order.</p>
</li>
<li>
<p><strong>results()</strong> returns a <code>ResultStore</code> containing all command outputs, which we can query by path.</p>
</li>
</ol>
<h2 id="running-examples"><a class="header" href="#running-examples">Running Examples</a></h2>
<p>The Panopticon repository includes several examples demonstrating different features. To run them:</p>
<pre><code class="language-bash"># Clone the repository
git clone https://github.com/dolly-parseton/panopticon.git
cd panopticon

# Run the multi-format loading example
cargo run --example multi_format_load

# Run the aggregation example
cargo run --example aggregate_and_export

# Run the conditional execution example
cargo run --example when_conditional
</code></pre>
<p>Each example is self-contained and includes comments explaining what it demonstrates.</p>
<h3 id="available-examples"><a class="header" href="#available-examples">Available Examples</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Example</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>multi_format_load</code></td><td>Loading CSV, JSON, and Parquet files</td></tr>
<tr><td><code>aggregate_and_export</code></td><td>Aggregation operations and result export</td></tr>
<tr><td><code>when_conditional</code></td><td>Conditional command execution</td></tr>
<tr><td><code>template_inheritance</code></td><td>Tera template inheritance patterns</td></tr>
<tr><td><code>iterate_object_keys</code></td><td>Iterating over dynamic data</td></tr>
<tr><td><code>pipeline_reuse</code></td><td>Reusing pipeline definitions</td></tr>
<tr><td><code>custom_command</code></td><td>Building your own commands</td></tr>
<tr><td><code>command_spec_safety</code></td><td>Command specification validation</td></tr>
</tbody>
</table>
</div>
<h2 id="project-structure"><a class="header" href="#project-structure">Project Structure</a></h2>
<p>A typical Panopticon project follows this structure:</p>
<pre><code>my-pipeline/
├── Cargo.toml
├── src/
│   └── main.rs          # Pipeline definition and execution
├── templates/           # Tera templates (if using TemplateCommand)
│   └── report.html
└── data/                # Input data files
    ├── input.csv
    └── config.json
</code></pre>
<p>For larger projects, we recommend organizing pipelines into modules:</p>
<pre><code>my-pipeline/
├── Cargo.toml
├── src/
│   ├── main.rs
│   ├── pipelines/
│   │   ├── mod.rs
│   │   ├── etl.rs       # ETL pipeline
│   │   └── reports.rs   # Reporting pipeline
│   └── commands/        # Custom commands (if extending)
│       └── mod.rs
└── ...
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Now that we have a basic pipeline running, we are ready to explore the core concepts:</p>
<ul>
<li><a href="#core-concepts">Core Concepts</a> - Understand the pipeline state machine, namespaces, and data stores</li>
<li><a href="#built-in-commands-1">Commands Overview</a> - Learn about the built-in commands available</li>
<li><a href="#working-with-data">Working with Data</a> - Master store paths and data access patterns</li>
</ul>
<p>If you want to build custom commands for your specific use case, see the <a href="../extending/src/introduction.html">Extending Panopticon</a> guide.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="core-concepts"><a class="header" href="#core-concepts">Core Concepts</a></h1>
<p>Panopticon is built around a small set of interlocking concepts that, once understood, make the library predictable and composable. This section walks through the mental model we use when designing pipelines.</p>
<h2 id="the-big-picture"><a class="header" href="#the-big-picture">The Big Picture</a></h2>
<p>A Panopticon pipeline is a declarative data processing workflow. Rather than writing imperative code that fetches data, transforms it, and stores results, we describe <em>what</em> we want to happen and let the library figure out the execution details.</p>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│                         Pipeline                                │
│  ┌───────────────────────────────────────────────────────────┐  │
│  │                      Namespaces                           │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │  │
│  │  │   "data"    │  │   "query"   │  │   "stats"   │        │  │
│  │  │   (Once)    │  │   (Once)    │  │ (Iterative) │        │  │
│  │  │  ┌───────┐  │  │  ┌───────┐  │  │  ┌───────┐  │        │  │
│  │  │  │Command│  │  │  │Command│  │  │  │Command│  │        │  │
│  │  │  └───────┘  │  │  └───────┘  │  │  └───────┘  │        │  │
│  │  └─────────────┘  └─────────────┘  └─────────────┘        │  │
│  └───────────────────────────────────────────────────────────┘  │
│                              │                                  │
│                              ▼                                  │
│  ┌───────────────────────────────────────────────────────────┐  │
│  │                     Data Stores                           │  │
│  │     ScalarStore (JSON-like values)                        │  │
│  │     TabularStore (Polars DataFrames)                      │  │
│  └───────────────────────────────────────────────────────────┘  │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<h3 id="pipeline-state-machine"><a class="header" href="#pipeline-state-machine"><a href="#pipeline-state-machine-1">Pipeline State Machine</a></a></h3>
<p>Pipelines progress through three states: <strong>Draft</strong>, <strong>Ready</strong>, and <strong>Completed</strong>. This state machine prevents common errors like modifying a running pipeline or executing an incomplete one. We use Rust’s type system to enforce these transitions at compile time.</p>
<h3 id="namespaces"><a class="header" href="#namespaces"><a href="#namespaces-1">Namespaces</a></a></h3>
<p>Namespaces group related commands and control how they execute. The three namespace types - <strong>Once</strong>, <strong>Iterative</strong>, and <strong>Static</strong> - let us express single operations, loops over data, and constant configuration respectively.</p>
<h3 id="commands-and-attributes"><a class="header" href="#commands-and-attributes"><a href="#commands-and-attributes-1">Commands and Attributes</a></a></h3>
<p>Commands are the units of work in a pipeline. Each command has a type (like <code>FileCommand</code> or <code>SqlCommand</code>), a name, and attributes that configure its behavior. We configure commands using the <code>ObjectBuilder</code> pattern for type-safe attribute construction.</p>
<h3 id="data-stores"><a class="header" href="#data-stores"><a href="#data-stores-1">Data Stores</a></a></h3>
<p>All data flows through two stores: the <strong>ScalarStore</strong> for JSON-like values (strings, numbers, objects, arrays) and the <strong>TabularStore</strong> for Polars DataFrames. Commands read from and write to these stores using <strong>StorePaths</strong> - dot-separated addresses like <code>data.load.users.data</code>.</p>
<h2 id="how-they-fit-together"><a class="header" href="#how-they-fit-together">How They Fit Together</a></h2>
<p>Here is the typical flow of a Panopticon pipeline:</p>
<ol>
<li><strong>Build</strong> - We create a <code>Pipeline&lt;Draft&gt;</code>, add namespaces, and configure commands with attributes</li>
<li><strong>Compile</strong> - We call <code>.compile()</code> to validate the pipeline and transition to <code>Pipeline&lt;Ready&gt;</code></li>
<li><strong>Execute</strong> - We call <code>.execute()</code> to run all commands, transitioning to <code>Pipeline&lt;Completed&gt;</code></li>
<li><strong>Collect</strong> - We call <code>.results()</code> to gather outputs from the data stores</li>
<li><strong>Iterate</strong> (optional) - We call <code>.edit()</code> to return to Draft state and add more commands</li>
</ol>
<p>This lifecycle ensures that pipelines are valid before execution and that results are only accessible after completion. The following sections dive deeper into each concept.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="pipeline-state-machine-1"><a class="header" href="#pipeline-state-machine-1">Pipeline State Machine</a></h1>
<p>The <code>Pipeline</code> type in Panopticon uses a compile-time state machine to enforce correct usage. This pattern prevents entire categories of bugs - we cannot accidentally execute an incomplete pipeline, modify one that is running, or access results that do not yet exist.</p>
<h2 id="the-three-states"><a class="header" href="#the-three-states">The Three States</a></h2>
<pre><code>┌─────────┐    compile()    ┌─────────┐    execute()    ┌───────────┐
│  Draft  │ ──────────────▶ │  Ready  │ ──────────────▶ │ Completed │
└─────────┘                 └─────────┘                 └───────────┘
     ▲                           │                           │
     │         edit()            │          edit()           │
     └───────────────────────────┴───────────────────────────┘
</code></pre>
<h3 id="draft"><a class="header" href="#draft">Draft</a></h3>
<p>A <code>Pipeline&lt;Draft&gt;</code> is under construction. In this state we can:</p>
<ul>
<li>Add namespaces with <code>add_namespace()</code></li>
<li>Add commands to namespaces via the returned <code>NamespaceHandle</code></li>
<li>Configure services and options</li>
</ul>
<p>We <strong>cannot</strong> execute a Draft pipeline. The <code>.execute()</code> method simply does not exist on this type.</p>
<h3 id="ready"><a class="header" href="#ready">Ready</a></h3>
<p>A <code>Pipeline&lt;Ready&gt;</code> has passed validation and is prepared for execution. The transition from Draft to Ready happens via <code>.compile()</code>, which performs several checks:</p>
<ul>
<li>Namespace names are unique and not reserved</li>
<li>Command names are unique within their namespace</li>
<li>Iterative namespaces have valid store paths</li>
<li>Command attributes pass schema validation</li>
<li>The execution plan is valid (no circular dependencies)</li>
</ul>
<p>From Ready, we can either:</p>
<ul>
<li>Call <code>.execute()</code> to run the pipeline</li>
<li>Call <code>.edit()</code> to return to Draft state for modifications</li>
</ul>
<h3 id="completed"><a class="header" href="#completed">Completed</a></h3>
<p>A <code>Pipeline&lt;Completed&gt;</code> has finished executing all commands. The execution context containing all results is stored in the Completed state. From here we can:</p>
<ul>
<li>Call <code>.results()</code> to collect outputs into a <code>ResultStore</code></li>
<li>Call <code>.restart()</code> to return to Ready state and re-execute</li>
<li>Call <code>.edit()</code> to return to Draft state and add more commands</li>
</ul>
<h2 id="why-a-state-machine"><a class="header" href="#why-a-state-machine">Why a State Machine?</a></h2>
<p>This design is intentional. Consider what could go wrong without it:</p>
<p><strong>Without state machine:</strong></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Hypothetical bad API - don't do this
let pipeline = Pipeline::new();
pipeline.add_command(...);
let results = pipeline.execute();  // What if add_command() failed?
pipeline.add_command(...);         // Modifying during execution?
let more_results = pipeline.results();  // Which execution?
<span class="boring">}</span></code></pre>
<p><strong>With state machine:</strong></p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// The actual API - compile-time guarantees
let mut pipeline = Pipeline::new();           // Draft
pipeline.add_namespace(...).await?;           // Still Draft

let ready = pipeline.compile().await?;        // Ready - validated!
let completed = ready.execute().await?;       // Completed - all commands ran

let results = completed.results(...).await?;  // Results available
let pipeline = completed.edit();              // Back to Draft
<span class="boring">}</span></code></pre>
<p>The type system prevents us from calling methods that do not make sense in the current state. If we try to call <code>.execute()</code> on a Draft pipeline, we get a compile error - not a runtime panic.</p>
<h2 id="practical-example-pipeline-reuse"><a class="header" href="#practical-example-pipeline-reuse">Practical Example: Pipeline Reuse</a></h2>
<p>One powerful pattern enabled by the state machine is incremental pipeline building. We can execute a pipeline, inspect results, then add more processing steps:</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    // ===== Pass 1: Load data and query =====
    println!("=== Pass 1: Load + Query ===\n");

    let mut pipeline = Pipeline::new();

    // Load users
    let file_attrs = ObjectBuilder::new()
        .insert(
            "files",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "users")
                    .insert("file", "fixtures/users.csv")
                    .insert("format", "csv")
                    .build_scalar(),
            ]),
        )
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("data"))
        .await?
        .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
        .await?;

    // Query: all users sorted by age
    let sql_attrs = ObjectBuilder::new()
        .insert(
            "tables",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "users")
                    .insert("source", "data.load.users.data")
                    .build_scalar(),
            ]),
        )
        .insert("query", "SELECT name, age FROM users ORDER BY age DESC")
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("query"))
        .await?
        .add_command::&lt;SqlCommand&gt;("sorted", &amp;sql_attrs)
        .await?;

    // Execute pass 1: Draft -&gt; Ready -&gt; Completed
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;
    println!("  Namespaces in pass 1: data, query");

    // ===== Pass 2: Edit pipeline, add aggregation, re-execute =====
    println!("\n=== Pass 2: Edit + Aggregate ===\n");

    // Return to Draft state - all previous namespaces and commands preserved
    let mut pipeline = completed.edit();

    // Add an aggregation namespace to the existing pipeline
    let agg_attrs = ObjectBuilder::new()
        .insert("source", "data.load.users.data")
        .insert(
            "aggregations",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "user_count")
                    .insert("op", "count")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "avg_age")
                    .insert("column", "age")
                    .insert("op", "mean")
                    .build_scalar(),
            ]),
        )
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("stats"))
        .await?
        .add_command::&lt;AggregateCommand&gt;("users", &amp;agg_attrs)
        .await?;

    // Re-compile and execute
    let completed = pipeline.compile().await?.execute().await?;
    println!("  Namespaces in pass 2: data, query, stats");
    println!("\nPipeline successfully edited and re-executed.");

    Ok(())
}</code></pre>
<p>The key insight is that calling <code>.edit()</code> on a Completed pipeline returns us to Draft while preserving all existing namespaces and commands. We can then add more processing steps and re-execute.</p>
<h2 id="state-transitions-summary"><a class="header" href="#state-transitions-summary">State Transitions Summary</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>From</th><th>To</th><th>Method</th><th>What Happens</th></tr>
</thead>
<tbody>
<tr><td>Draft</td><td>Ready</td><td><code>.compile()</code></td><td>Validates pipeline configuration</td></tr>
<tr><td>Ready</td><td>Completed</td><td><code>.execute()</code></td><td>Runs all commands</td></tr>
<tr><td>Ready</td><td>Draft</td><td><code>.edit()</code></td><td>Returns to editing mode</td></tr>
<tr><td>Completed</td><td>Draft</td><td><code>.edit()</code></td><td>Returns to editing mode</td></tr>
<tr><td>Completed</td><td>Ready</td><td><code>.restart()</code></td><td>Clears results, ready to re-execute</td></tr>
</tbody>
</table>
</div>
<h2 id="implementation-details"><a class="header" href="#implementation-details">Implementation Details</a></h2>
<p>For those curious about the implementation, Panopticon uses Rust’s type system to encode states:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Marker types for states
pub struct Draft;
pub struct Ready;
pub struct Completed {
    context: ExecutionContext,
}

// Generic pipeline parameterized by state
pub struct Pipeline&lt;T = Draft&gt; {
    pub(crate) services: PipelineServices,
    pub(crate) namespaces: Vec&lt;Namespace&gt;,
    pub(crate) commands: Vec&lt;CommandSpec&gt;,
    state: T,
}
<span class="boring">}</span></code></pre>
<p>Each state has its own <code>impl Pipeline&lt;State&gt;</code> block defining only the methods valid for that state. The <code>Completed</code> state holds the <code>ExecutionContext</code> containing all results, which is why <code>.results()</code> is only available on <code>Pipeline&lt;Completed&gt;</code>.</p>
<p>This pattern is sometimes called the “typestate” pattern in Rust. It moves invariant checking from runtime to compile time, resulting in APIs that are impossible to misuse.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="namespaces-1"><a class="header" href="#namespaces-1">Namespaces</a></h1>
<p>Namespaces are the organizational unit in Panopticon. Every command belongs to exactly one namespace, and the namespace type determines how those commands execute.</p>
<h2 id="the-three-namespace-types"><a class="header" href="#the-three-namespace-types">The Three Namespace Types</a></h2>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│                        Namespace Types                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   Once        Execute commands once, in order                   │
│   ─────────────────────────────────────────────                 │
│   [cmd1] → [cmd2] → [cmd3]                                      │
│                                                                 │
│   Iterative   Execute commands once per item in a collection    │
│   ─────────────────────────────────────────────                 │
│   for item in collection:                                       │
│       [cmd1] → [cmd2] → [cmd3]                                  │
│                                                                 │
│   Static      No commands, just provides constant values        │
│   ─────────────────────────────────────────────                 │
│   { key1: value1, key2: value2 }                                │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h3 id="once-namespaces"><a class="header" href="#once-namespaces">Once Namespaces</a></h3>
<p>The <code>Once</code> namespace is the default. Commands in a Once namespace execute exactly once, in the order they were added.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create a Once namespace (the default)
pipeline
    .add_namespace(NamespaceBuilder::new("data"))
    .await?
    .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<p>This is the most common namespace type. Use it for:</p>
<ul>
<li>Loading data from files or APIs</li>
<li>Running SQL queries</li>
<li>Performing one-time transformations</li>
</ul>
<h3 id="iterative-namespaces"><a class="header" href="#iterative-namespaces">Iterative Namespaces</a></h3>
<p><code>Iterative</code> namespaces execute their commands once for each item in a collection. The collection can come from:</p>
<ul>
<li>An array in the scalar store</li>
<li>Object keys from a JSON object</li>
<li>A column in a DataFrame</li>
<li>A string split by a delimiter</li>
</ul>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create an Iterative namespace that loops over object keys
let mut handle = pipeline
    .add_namespace(
        NamespaceBuilder::new("classify")
            .iterative()
            .store_path(StorePath::from_segments(["config", "regions"]))
            .scalar_object_keys(None, false)
            .iter_var("region")
            .index_var("idx"),
    )
    .await?;

handle
    .add_command::&lt;ConditionCommand&gt;("check", &amp;condition_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<p>During execution, Panopticon:</p>
<ol>
<li>Resolves the collection from the store path</li>
<li>For each item, sets the iteration variables (<code>region</code> and <code>idx</code> in this example)</li>
<li>Executes all commands in the namespace</li>
<li>Cleans up the iteration variables</li>
</ol>
<p>Results from iterative commands are indexed. Instead of storing at <code>classify.check.result</code>, we store at <code>classify.check[0].result</code>, <code>classify.check[1].result</code>, etc.</p>
<h3 id="static-namespaces"><a class="header" href="#static-namespaces">Static Namespaces</a></h3>
<p><code>Static</code> namespaces contain no commands - they exist purely to provide constant values to the data stores. Think of them as configuration namespaces.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create a Static namespace with configuration values
pipeline
    .add_namespace(
        NamespaceBuilder::new("config")
            .static_ns()
            .insert("api_version", ScalarValue::String("v2".into()))
            .insert(
                "regions",
                ObjectBuilder::new()
                    .insert("us-east", "Virginia")
                    .insert("us-west", "Oregon")
                    .insert("eu-west", "Ireland")
                    .build_scalar(),
            ),
    )
    .await?;
<span class="boring">}</span></code></pre>
<p>Values from static namespaces are available to all subsequent commands via Tera templating:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In a later command's attributes
.insert("endpoint", "https://api.example.com/{{ config.api_version }}/data")
<span class="boring">}</span></code></pre>
<h2 id="iteration-sources"><a class="header" href="#iteration-sources">Iteration Sources</a></h2>
<p>Iterative namespaces support several source types for determining what to iterate over:</p>
<h3 id="scalararray"><a class="header" href="#scalararray">ScalarArray</a></h3>
<p>Iterate over elements in a JSON array:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>NamespaceBuilder::new("process")
    .iterative()
    .store_path(StorePath::from_segments(["data", "items"]))
    .scalar_array(None)  // None = all items, Some((start, end)) = range
    .iter_var("item")
<span class="boring">}</span></code></pre>
<h3 id="scalarobjectkeys"><a class="header" href="#scalarobjectkeys">ScalarObjectKeys</a></h3>
<p>Iterate over keys of a JSON object:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>NamespaceBuilder::new("classify")
    .iterative()
    .store_path(StorePath::from_segments(["config", "regions"]))
    .scalar_object_keys(None, false)  // None = all keys, Some(vec) = filter
    .iter_var("region")
<span class="boring">}</span></code></pre>
<p>The second parameter controls exclusion - <code>true</code> means “iterate over all keys <em>except</em> those listed”.</p>
<h3 id="scalarstringsplit"><a class="header" href="#scalarstringsplit">ScalarStringSplit</a></h3>
<p>Iterate over parts of a delimited string:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>NamespaceBuilder::new("tags")
    .iterative()
    .store_path(StorePath::from_segments(["data", "tag_list"]))
    .string_split(",")
    .iter_var("tag")
<span class="boring">}</span></code></pre>
<h3 id="tabularcolumn"><a class="header" href="#tabularcolumn">TabularColumn</a></h3>
<p>Iterate over unique values in a DataFrame column:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>NamespaceBuilder::new("by_category")
    .iterative()
    .store_path(StorePath::from_segments(["data", "products", "data"]))
    .tabular_column("category", None)
    .iter_var("category")
<span class="boring">}</span></code></pre>
<h2 id="complete-example-object-key-iteration"><a class="header" href="#complete-example-object-key-iteration">Complete Example: Object Key Iteration</a></h2>
<p>Here is a full example showing how to iterate over object keys:</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let mut pipeline = Pipeline::new();

    // --- Static namespace: an object whose keys we will iterate ---
    pipeline
        .add_namespace(
            NamespaceBuilder::new("config").static_ns().insert(
                "regions",
                ObjectBuilder::new()
                    .insert("us-east", "Virginia")
                    .insert("us-west", "Oregon")
                    .insert("eu-west", "Ireland")
                    .build_scalar(),
            ),
        )
        .await?;

    // --- Iterative namespace: loop over each region key ---
    let condition_attrs = ObjectBuilder::new()
        .insert(
            "branches",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "is_us")
                    .insert("if", "region is starting_with(\"us-\")")
                    .insert("then", "Region {{ region }} is in the US")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "is_eu")
                    .insert("if", "region is starting_with(\"eu-\")")
                    .insert("then", "Region {{ region }} is in the EU")
                    .build_scalar(),
            ]),
        )
        .insert("default", "Region {{ region }} is in an unknown area")
        .build_hashmap();

    let mut handle = pipeline
        .add_namespace(
            NamespaceBuilder::new("classify")
                .iterative()
                .store_path(StorePath::from_segments(["config", "regions"]))
                .scalar_object_keys(None, false)
                .iter_var("region")
                .index_var("idx"),
        )
        .await?;
    handle
        .add_command::&lt;ConditionCommand&gt;("region", &amp;condition_attrs)
        .await?;

    // --- Execute ---
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;

    // --- Print results per iteration ---
    println!("=== Iterating over region keys ===\n");

    let mut idx = 0;
    loop {
        let source = StorePath::from_segments(["classify", "region"]).with_index(idx);
        let Some(cmd_results) = results.get_by_source(&amp;source) else {
            break;
        };

        let result = cmd_results
            .data_get(&amp;source.with_segment("result"))
            .and_then(|r| r.as_scalar())
            .expect("Expected result");
        println!("  [{}] {}", idx, result.1);

        idx += 1;
    }

    println!("\nProcessed {} region(s)", idx);

    Ok(())
}</code></pre>
<p>Output:</p>
<pre><code>=== Iterating over region keys ===

  [0] Region us-east is in the US
  [1] Region us-west is in the US
  [2] Region eu-west is in the EU

Processed 3 region(s)
</code></pre>
<h2 id="reserved-names"><a class="header" href="#reserved-names">Reserved Names</a></h2>
<p>Two namespace names are reserved and cannot be used:</p>
<ul>
<li><code>item</code> - Default iteration variable name</li>
<li><code>index</code> - Default index variable name</li>
</ul>
<p>If you try to create a namespace with a reserved name, the builder will return an error.</p>
<h2 id="namespace-execution-order"><a class="header" href="#namespace-execution-order">Namespace Execution Order</a></h2>
<p>Namespaces execute in the order they were added to the pipeline. This is important because later namespaces can reference data produced by earlier ones.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 1. Load data (executes first)
pipeline.add_namespace(NamespaceBuilder::new("data")).await?;

// 2. Query the loaded data (executes second)
pipeline.add_namespace(NamespaceBuilder::new("query")).await?;

// 3. Aggregate the query results (executes third)
pipeline.add_namespace(NamespaceBuilder::new("stats")).await?;
<span class="boring">}</span></code></pre>
<p>Within a namespace, commands also execute in order. The combination of namespace ordering and command ordering gives us predictable, deterministic pipeline execution.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="commands-and-attributes-1"><a class="header" href="#commands-and-attributes-1">Commands and Attributes</a></h1>
<p>Commands are the workhorses of Panopticon. Each command performs a specific operation - loading files, running SQL queries, evaluating conditions, and so on. We configure commands through attributes, which are key-value pairs that control the command’s behavior.</p>
<h2 id="the-command-trait"><a class="header" href="#the-command-trait">The Command Trait</a></h2>
<p>Under the hood, a command is any type that implements three traits:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Command: FromAttributes + Descriptor + Executable {}
<span class="boring">}</span></code></pre>
<ul>
<li><strong>FromAttributes</strong> - Constructs the command from an attribute map</li>
<li><strong>Descriptor</strong> - Provides metadata (type name, attribute schema, result schema)</li>
<li><strong>Executable</strong> - Performs the actual work during pipeline execution</li>
</ul>
<p>Panopticon provides a blanket implementation, so any type implementing the three base traits automatically implements <code>Command</code>.</p>
<h2 id="adding-commands-to-a-pipeline"><a class="header" href="#adding-commands-to-a-pipeline">Adding Commands to a Pipeline</a></h2>
<p>Commands are always added to a namespace. The pattern looks like this:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut handle = pipeline
    .add_namespace(NamespaceBuilder::new("data"))
    .await?;

handle
    .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<p>The turbofish syntax <code>&lt;FileCommand&gt;</code> tells Panopticon which command type to use. The string <code>"load"</code> is the command’s name within this namespace, which becomes part of the store path for its results (<code>data.load.*</code>).</p>
<h2 id="building-attributes-with-objectbuilder"><a class="header" href="#building-attributes-with-objectbuilder">Building Attributes with ObjectBuilder</a></h2>
<p>Attributes are a <code>HashMap&lt;String, ScalarValue&gt;</code>. While we could construct this manually, <code>ObjectBuilder</code> provides a more ergonomic interface:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let file_attrs = ObjectBuilder::new()
    .insert(
        "files",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "users")
                .insert("file", "data/users.csv")
                .insert("format", "csv")
                .build_scalar(),
        ]),
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="objectbuilder-methods"><a class="header" href="#objectbuilder-methods">ObjectBuilder Methods</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Method</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>new()</code></td><td>Create a new empty builder</td></tr>
<tr><td><code>insert(key, value)</code></td><td>Add a key-value pair</td></tr>
<tr><td><code>object(key, nested)</code></td><td>Add a nested ObjectBuilder</td></tr>
<tr><td><code>build_scalar()</code></td><td>Convert to a <code>ScalarValue::Object</code></td></tr>
<tr><td><code>build_hashmap()</code></td><td>Convert to <code>HashMap&lt;String, ScalarValue&gt;</code></td></tr>
</tbody>
</table>
</div>
<h3 id="nested-objects"><a class="header" href="#nested-objects">Nested Objects</a></h3>
<p>For complex attribute structures, we can nest ObjectBuilders:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert("name", "report")
    .object("options",
        ObjectBuilder::new()
            .insert("format", "json")
            .insert("pretty", true)
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<p>This produces the equivalent of:</p>
<pre><code class="language-json">{
    "name": "report",
    "options": {
        "format": "json",
        "pretty": true
    }
}
</code></pre>
<h3 id="arrays-of-objects"><a class="header" href="#arrays-of-objects">Arrays of Objects</a></h3>
<p>Many commands accept arrays of configuration objects:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "aggregations",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "total")
                .insert("op", "sum")
                .insert("column", "amount")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "average")
                .insert("op", "mean")
                .insert("column", "amount")
                .build_scalar(),
        ]),
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="common-attributes"><a class="header" href="#common-attributes">Common Attributes</a></h2>
<p>All commands support a <code>when</code> attribute for conditional execution:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert("when", "data.load.status == \"success\"")
    // ... other attributes
    .build_hashmap();
<span class="boring">}</span></code></pre>
<p>The <code>when</code> attribute is evaluated as a Tera expression. If it evaluates to a falsy value, the command is skipped and its status is set to <code>"skipped"</code>.</p>
<h2 id="attribute-validation"><a class="header" href="#attribute-validation">Attribute Validation</a></h2>
<p>When a pipeline compiles, Panopticon validates all command attributes against their schemas. Each command type declares:</p>
<ul>
<li><strong>Required attributes</strong> - Must be present</li>
<li><strong>Optional attributes</strong> - May be omitted</li>
<li><strong>Type constraints</strong> - Values must match expected types</li>
</ul>
<p>If validation fails, <code>.compile()</code> returns an error describing what is wrong.</p>
<h2 id="command-results"><a class="header" href="#command-results">Command Results</a></h2>
<p>Every command produces results, which are stored at paths derived from the namespace and command name. All commands automatically produce:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>status</code></td><td>String</td><td><code>"success"</code>, <code>"skipped"</code>, <code>"error"</code>, or <code>"cancelled"</code></td></tr>
<tr><td><code>duration_ms</code></td><td>Number</td><td>Execution time in milliseconds</td></tr>
</tbody>
</table>
</div>
<p>Commands also produce their own specific results. For example, <code>ConditionCommand</code> produces:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>result</code></td><td>String</td><td>The value from the matched branch or default</td></tr>
<tr><td><code>matched</code></td><td>Bool</td><td>Whether a branch condition matched</td></tr>
<tr><td><code>branch_index</code></td><td>Number</td><td>Index of matched branch, or -1 for default</td></tr>
</tbody>
</table>
</div>
<h2 id="result-kinds-meta-vs-data"><a class="header" href="#result-kinds-meta-vs-data">Result Kinds: Meta vs Data</a></h2>
<p>Results are categorized as either <strong>Meta</strong> or <strong>Data</strong>:</p>
<ul>
<li><strong>Meta</strong> results describe the execution (status, duration, row counts)</li>
<li><strong>Data</strong> results contain the actual output (query results, computed values)</li>
</ul>
<p>This distinction matters when collecting results - we might want to include all data but only summary metadata.</p>
<h2 id="example-conditioncommand"><a class="header" href="#example-conditioncommand">Example: ConditionCommand</a></h2>
<p>Let us walk through a complete example using <code>ConditionCommand</code>:</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let mut pipeline = Pipeline::new();

    // Static config providing a value to check
    pipeline
        .add_namespace(
            NamespaceBuilder::new("input")
                .static_ns()
                .insert("score", ScalarValue::Number(85.into())),
        )
        .await?;

    // Condition command to classify the score
    let condition_attrs = ObjectBuilder::new()
        .insert(
            "branches",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "excellent")
                    .insert("if", "input.score &gt;= 90")
                    .insert("then", "Excellent work!")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "good")
                    .insert("if", "input.score &gt;= 70")
                    .insert("then", "Good job!")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "needs_work")
                    .insert("if", "input.score &gt;= 50")
                    .insert("then", "Keep practicing!")
                    .build_scalar(),
            ]),
        )
        .insert("default", "Please try again.")
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("classify"))
        .await?
        .add_command::&lt;ConditionCommand&gt;("score", &amp;condition_attrs)
        .await?;

    // Execute
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;

    // Get the result
    let source = StorePath::from_segments(["classify", "score"]);
    let cmd_results = results.get_by_source(&amp;source).expect("Expected results");

    let result = cmd_results
        .data_get(&amp;source.with_segment("result"))
        .and_then(|r| r.as_scalar())
        .expect("Expected result");

    println!("Classification: {}", result.1);  // "Good job!"

    Ok(())
}</code></pre>
<h2 id="built-in-commands"><a class="header" href="#built-in-commands">Built-in Commands</a></h2>
<p>Panopticon provides several built-in commands:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Command</th><th>Purpose</th></tr>
</thead>
<tbody>
<tr><td><code>FileCommand</code></td><td>Load data from CSV, JSON, or Parquet files</td></tr>
<tr><td><code>SqlCommand</code></td><td>Run SQL queries against loaded DataFrames</td></tr>
<tr><td><code>AggregateCommand</code></td><td>Compute aggregations (sum, mean, count, etc.)</td></tr>
<tr><td><code>ConditionCommand</code></td><td>Evaluate conditional logic with branches</td></tr>
<tr><td><code>TemplateCommand</code></td><td>Generate text using Tera templates</td></tr>
</tbody>
</table>
</div>
<p>Each command has its own attribute schema documented in the <a href="#built-in-commands-1">Commands</a> section.</p>
<h2 id="tera-substitution-in-attributes"><a class="header" href="#tera-substitution-in-attributes">Tera Substitution in Attributes</a></h2>
<p>String attributes support Tera template syntax. Before a command executes, Panopticon substitutes any <code>{{ ... }}</code> expressions with values from the scalar store:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert("query", "SELECT * FROM users WHERE region = '{{ config.region }}'")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<p>This enables dynamic configuration based on earlier command results or static namespace values.</p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>The command system in Panopticon follows a consistent pattern:</p>
<ol>
<li>Commands implement <code>FromAttributes</code>, <code>Descriptor</code>, and <code>Executable</code></li>
<li>We add commands to namespaces using <code>add_command::&lt;T&gt;(name, &amp;attrs)</code></li>
<li>Attributes are built using <code>ObjectBuilder</code> for type safety</li>
<li>All commands support the <code>when</code> attribute for conditional execution</li>
<li>Results are stored at <code>namespace.command.field</code> paths</li>
<li>String attributes support Tera templating for dynamic values</li>
</ol>
<p>This design keeps command configuration declarative while enabling powerful dynamic behavior through templating and conditional execution.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="data-stores-1"><a class="header" href="#data-stores-1">Data Stores</a></h1>
<p>All data in a Panopticon pipeline flows through two stores: the <strong>ScalarStore</strong> for JSON-like values and the <strong>TabularStore</strong> for Polars DataFrames. Understanding these stores is essential for working with command inputs and outputs.</p>
<h2 id="two-stores-two-data-models"><a class="header" href="#two-stores-two-data-models">Two Stores, Two Data Models</a></h2>
<pre><code>┌─────────────────────────────────────────────────────────────────┐
│                      ExecutionContext                           │
│                                                                 │
│  ┌─────────────────────────────┐  ┌─────────────────────────┐   │
│  │        ScalarStore          │  │      TabularStore       │   │
│  │                             │  │                         │   │
│  │  • Strings                  │  │  • Polars DataFrames    │   │
│  │  • Numbers                  │  │  • Columnar data        │   │
│  │  • Booleans                 │  │  • SQL-queryable        │   │
│  │  • Arrays                   │  │                         │   │
│  │  • Objects (nested)         │  │                         │   │
│  │  • Null                     │  │                         │   │
│  │                             │  │                         │   │
│  │  Backed by Tera Context     │  │  HashMap&lt;String, DF&gt;    │   │
│  │  (enables templating)       │  │                         │   │
│  └─────────────────────────────┘  └─────────────────────────┘   │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
</code></pre>
<h3 id="scalarstore"><a class="header" href="#scalarstore">ScalarStore</a></h3>
<p>The ScalarStore holds JSON-like values. Internally, it wraps a Tera context, which means all scalar values are automatically available for template substitution.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub type ScalarValue = tera::Value;  // Re-export of serde_json::Value
<span class="boring">}</span></code></pre>
<p>Scalar values can be:</p>
<ul>
<li><strong>Null</strong> - Absence of a value</li>
<li><strong>Bool</strong> - <code>true</code> or <code>false</code></li>
<li><strong>Number</strong> - Integers or floating-point</li>
<li><strong>String</strong> - Text data</li>
<li><strong>Array</strong> - Ordered list of values</li>
<li><strong>Object</strong> - Key-value map (nested structure)</li>
</ul>
<h3 id="tabularstore"><a class="header" href="#tabularstore">TabularStore</a></h3>
<p>The TabularStore holds Polars DataFrames - efficient columnar data structures ideal for analytical queries.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub type TabularValue = polars::prelude::DataFrame;
<span class="boring">}</span></code></pre>
<p>DataFrames are stored by their full store path (as a dotted string key). Commands like <code>SqlCommand</code> can register these as tables and query across them.</p>
<h2 id="store-paths"><a class="header" href="#store-paths">Store Paths</a></h2>
<p>Values in both stores are addressed using <code>StorePath</code> - a structured path that typically follows the pattern <code>namespace.command.field</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create a store path
let path = StorePath::from_segments(["data", "load", "users", "data"]);

// Access with dotted notation
let dotted = path.to_dotted();  // "data.load.users.data"

// Add segments
let status_path = path.with_segment("status");  // "data.load.users.status"

// Add iteration index
let indexed = path.with_index(0);  // "data.load.users[0]"
<span class="boring">}</span></code></pre>
<p>Store paths provide a consistent way to reference data throughout the pipeline.</p>
<h2 id="scalarvalue-operations"><a class="header" href="#scalarvalue-operations">ScalarValue Operations</a></h2>
<h3 id="creating-values"><a class="header" href="#creating-values">Creating Values</a></h3>
<p>Panopticon provides helper functions and the <code>ObjectBuilder</code> for creating scalar values:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

// Primitives convert automatically via Into&lt;ScalarValue&gt;
let string_val: ScalarValue = "hello".into();
let number_val: ScalarValue = 42.into();
let bool_val: ScalarValue = true.into();

// Arrays
let array_val = ScalarValue::Array(vec![
    "a".into(),
    "b".into(),
    "c".into(),
]);

// Objects using ObjectBuilder
let object_val = ObjectBuilder::new()
    .insert("name", "Alice")
    .insert("age", 30)
    .insert("active", true)
    .build_scalar();
<span class="boring">}</span></code></pre>
<h3 id="type-checking-and-extraction"><a class="header" href="#type-checking-and-extraction">Type Checking and Extraction</a></h3>
<p>ScalarValue provides methods for type checking and extraction:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Standard serde_json methods
if let Some(s) = value.as_str() { /* use string */ }
if let Some(n) = value.as_i64() { /* use integer */ }
if let Some(b) = value.as_bool() { /* use boolean */ }
if let Some(arr) = value.as_array() { /* use array */ }
if let Some(obj) = value.as_object() { /* use object */ }

// Extension trait with error handling
use panopticon_core::prelude::ScalarAsExt;

let name = value.as_str_or_err("name")?;      // Returns Result
let count = value.as_i64_or_err("count")?;
let items = value.as_array_or_err("items")?;
<span class="boring">}</span></code></pre>
<h3 id="map-extension-trait"><a class="header" href="#map-extension-trait">Map Extension Trait</a></h3>
<p>For working with object maps, the <code>ScalarMapExt</code> trait provides convenient accessors:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::ScalarMapExt;

let obj = value.as_object().unwrap();

// Required fields (returns Result)
let name = obj.get_required_string("name")?;
let count = obj.get_required_i64("count")?;
let enabled = obj.get_required_bool("enabled")?;

// Optional fields (returns Option)
let description = obj.get_optional_string("description");
let limit = obj.get_optional_i64("limit");
<span class="boring">}</span></code></pre>
<h2 id="how-commands-use-stores"><a class="header" href="#how-commands-use-stores">How Commands Use Stores</a></h2>
<p>Commands read inputs from and write outputs to the stores. Here is a typical pattern:</p>
<pre><code>┌──────────────┐         ┌─────────────┐         ┌──────────────┐
│ ScalarStore  │────────▶│   Command   │────────▶│ ScalarStore  │
│ (inputs)     │         │             │         │ (outputs)    │
└──────────────┘         │  - Read     │         └──────────────┘
                         │  - Process  │
┌──────────────┐         │  - Write    │         ┌──────────────┐
│ TabularStore │────────▶│             │────────▶│ TabularStore │
│ (inputs)     │         └─────────────┘         │ (outputs)    │
└──────────────┘                                 └──────────────┘
</code></pre>
<h3 id="filecommand-example"><a class="header" href="#filecommand-example">FileCommand Example</a></h3>
<p>When <code>FileCommand</code> loads a CSV file:</p>
<ol>
<li>Reads the file from disk (not from stores)</li>
<li>Writes DataFrame to TabularStore at <code>namespace.command.name.data</code></li>
<li>Writes metadata to ScalarStore:
<ul>
<li><code>namespace.command.name.rows</code> - Row count</li>
<li><code>namespace.command.name.columns</code> - Column count</li>
<li><code>namespace.command.status</code> - “success”</li>
<li><code>namespace.command.duration_ms</code> - Execution time</li>
</ul>
</li>
</ol>
<h3 id="sqlcommand-example"><a class="header" href="#sqlcommand-example">SqlCommand Example</a></h3>
<p>When <code>SqlCommand</code> runs a query:</p>
<ol>
<li>Reads DataFrames from TabularStore based on <code>tables</code> attribute</li>
<li>Registers them as SQL tables</li>
<li>Executes the query</li>
<li>Writes result DataFrame to TabularStore</li>
<li>Writes metadata to ScalarStore</li>
</ol>
<h2 id="template-substitution"><a class="header" href="#template-substitution">Template Substitution</a></h2>
<p>Because ScalarStore wraps a Tera context, all values are available for template substitution in command attributes:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Static namespace provides config
pipeline.add_namespace(
    NamespaceBuilder::new("config")
        .static_ns()
        .insert("region", "us-east")
        .insert("limit", ScalarValue::Number(100.into()))
).await?;

// SQL command uses templated query
let sql_attrs = ObjectBuilder::new()
    .insert("query", "SELECT * FROM users WHERE region = '{{ config.region }}' LIMIT {{ config.limit }}")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<p>During execution, Panopticon substitutes <code>{{ config.region }}</code> with <code>"us-east"</code> and <code>{{ config.limit }}</code> with <code>100</code> before the command runs.</p>
<h2 id="accessing-results"><a class="header" href="#accessing-results">Accessing Results</a></h2>
<p>After pipeline execution, we retrieve results through the <code>ResultStore</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

// Get results for a specific command
let source = StorePath::from_segments(["data", "load"]);
let cmd_results = results.get_by_source(&amp;source).expect("Expected results");

// Access metadata
let rows = cmd_results.meta_get(&amp;source.with_segment("rows"));

// Access data
let status = cmd_results.data_get(&amp;source.with_segment("result"));
<span class="boring">}</span></code></pre>
<h3 id="resultvalue-types"><a class="header" href="#resultvalue-types">ResultValue Types</a></h3>
<p>Results come in two forms:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum ResultValue {
    Scalar {
        ty: ScalarType,
        value: ScalarValue,
    },
    Tabular {
        path: PathBuf,      // File path where DataFrame was written
        format: OutputFormat,
        rows_count: usize,
        columns_count: usize,
    },
}
<span class="boring">}</span></code></pre>
<p>Tabular results are written to disk (CSV, JSON, or Parquet) and the <code>ResultValue</code> contains the path and summary statistics.</p>
<h2 id="scalartype-enum"><a class="header" href="#scalartype-enum">ScalarType Enum</a></h2>
<p>For type introspection, Panopticon provides a <code>ScalarType</code> enum:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum ScalarType {
    Null,
    Bool,
    Number,
    String,
    Array,
    Object,
}
<span class="boring">}</span></code></pre>
<p>This is useful for schema validation and result type checking.</p>
<h2 id="practical-example"><a class="header" href="#practical-example">Practical Example</a></h2>
<p>Here is a complete example showing data flow through the stores:</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let mut pipeline = Pipeline::new();

    // 1. Static namespace adds values to ScalarStore
    pipeline
        .add_namespace(
            NamespaceBuilder::new("config")
                .static_ns()
                .insert("threshold", ScalarValue::Number(50.into()))
        )
        .await?;

    // 2. FileCommand writes DataFrame to TabularStore
    let file_attrs = ObjectBuilder::new()
        .insert("files", ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "scores")
                .insert("file", "data/scores.csv")
                .insert("format", "csv")
                .build_scalar(),
        ]))
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("data"))
        .await?
        .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
        .await?;

    // 3. SqlCommand reads from TabularStore, uses ScalarStore for templating
    let sql_attrs = ObjectBuilder::new()
        .insert("tables", ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "scores")
                .insert("source", "data.load.scores.data")
                .build_scalar(),
        ]))
        .insert("query", "SELECT * FROM scores WHERE value &gt; {{ config.threshold }}")
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("filtered"))
        .await?
        .add_command::&lt;SqlCommand&gt;("high_scores", &amp;sql_attrs)
        .await?;

    // Execute and collect results
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;

    // 4. Results contain both scalar metadata and tabular file paths
    let source = StorePath::from_segments(["filtered", "high_scores"]);
    if let Some(cmd_results) = results.get_by_source(&amp;source) {
        // Metadata from ScalarStore
        if let Some(rows) = cmd_results.meta_get(&amp;source.with_segment("rows")) {
            println!("Filtered rows: {}", rows);
        }

        // Tabular data was written to file
        if let Some(result_value) = cmd_results.data_get(&amp;source.with_segment("data")) {
            if let Some((path, _format)) = result_value.as_tabular() {
                println!("Data written to: {}", path.display());
            }
        }
    }

    Ok(())
}</code></pre>
<h2 id="summary-1"><a class="header" href="#summary-1">Summary</a></h2>
<p>The dual-store architecture in Panopticon separates concerns:</p>
<ul>
<li><strong>ScalarStore</strong> handles configuration, metadata, and template substitution</li>
<li><strong>TabularStore</strong> handles large datasets efficiently with Polars</li>
</ul>
<p>This separation allows us to:</p>
<ul>
<li>Use JSON-like values for flexible configuration</li>
<li>Leverage Tera templating for dynamic attribute values</li>
<li>Process large datasets with columnar efficiency</li>
<li>Query across DataFrames using SQL</li>
</ul>
<p>Understanding how data flows through these stores is key to building effective Panopticon pipelines.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="built-in-commands-1"><a class="header" href="#built-in-commands-1">Built-in Commands</a></h1>
<p>Panopticon includes a set of built-in commands that cover common data pipeline operations. These commands work together to load, transform, analyze, and export data.</p>
<h2 id="command-overview"><a class="header" href="#command-overview">Command Overview</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Command</th><th>Purpose</th><th>Key Use Cases</th></tr>
</thead>
<tbody>
<tr><td><a href="#filecommand">FileCommand</a></td><td>Load data files</td><td>Read CSV, JSON, and Parquet files into the tabular store</td></tr>
<tr><td><a href="#sqlcommand">SqlCommand</a></td><td>Query tabular data</td><td>Filter, join, transform data using SQL syntax</td></tr>
<tr><td><a href="#aggregatecommand">AggregateCommand</a></td><td>Compute statistics</td><td>Calculate count, sum, mean, max, min, median, and more</td></tr>
<tr><td><a href="#conditioncommand">ConditionCommand</a></td><td>Branch logic</td><td>Evaluate Tera expressions to produce conditional outputs</td></tr>
<tr><td><a href="#templatecommand">TemplateCommand</a></td><td>Render templates</td><td>Generate files using Tera templates with inheritance</td></tr>
</tbody>
</table>
</div>
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<h3 id="data-loading-and-analysis"><a class="header" href="#data-loading-and-analysis">Data Loading and Analysis</a></h3>
<p>A typical pipeline starts by loading data with <code>FileCommand</code>, optionally transforms it with <code>SqlCommand</code>, and computes metrics with <code>AggregateCommand</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Load CSV data
pipeline
    .add_namespace(NamespaceBuilder::new("data"))
    .await?
    .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
    .await?;

// Query the loaded data
pipeline
    .add_namespace(NamespaceBuilder::new("query"))
    .await?
    .add_command::&lt;SqlCommand&gt;("filtered", &amp;query_attrs)
    .await?;

// Aggregate results
pipeline
    .add_namespace(NamespaceBuilder::new("stats"))
    .await?
    .add_command::&lt;AggregateCommand&gt;("summary", &amp;agg_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="conditional-execution"><a class="header" href="#conditional-execution">Conditional Execution</a></h3>
<p>All commands support the optional <code>when</code> attribute, which is a Tera expression evaluated at runtime. If it resolves to a falsy value, the command is skipped:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert("when", "inputs.feature_enabled")  // Skip if false
    .insert("source", "data.load.users.data")
    // ... other attributes
    .build_hashmap();
<span class="boring">}</span></code></pre>
<p>When a command is skipped:</p>
<ul>
<li>Its <code>status</code> meta result is set to <code>"skipped"</code></li>
<li>Data results are absent from the ResultStore</li>
<li>Dependent commands that reference its outputs will fail unless handled</li>
</ul>
<h3 id="store-path-references"><a class="header" href="#store-path-references">Store Path References</a></h3>
<p>Commands that consume data from earlier pipeline stages use <strong>store paths</strong> to reference results. Store paths are dot-separated strings that identify locations in the data stores:</p>
<pre><code>namespace.command.result_key
</code></pre>
<p>For example:</p>
<ul>
<li><code>data.load.users.data</code> - The tabular data loaded from users file</li>
<li><code>stats.summary.row_count</code> - A scalar aggregation result</li>
</ul>
<p>See <a href="#store-paths-2">Store Paths</a> for more details.</p>
<h3 id="tera-template-substitution"><a class="header" href="#tera-template-substitution">Tera Template Substitution</a></h3>
<p>Many command attributes support Tera template syntax for dynamic values. This is indicated by “supports Tera substitution” in the attribute documentation:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.insert("file", "{{ config.data_dir }}/users.csv")
.insert("query", "SELECT * FROM users WHERE status = '{{ inputs.status }}'")
<span class="boring">}</span></code></pre>
<p>The execution context automatically substitutes these expressions using values from the scalar store.</p>
<h2 id="result-types"><a class="header" href="#result-types">Result Types</a></h2>
<p>Commands produce two types of results:</p>
<h3 id="meta-results"><a class="header" href="#meta-results">Meta Results</a></h3>
<p>Metadata about the command execution (row counts, sizes, column lists). These are accessed via <code>meta_get()</code> on the command results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let row_count = cmd_results
    .meta_get(&amp;source.with_segment("rows"))
    .expect("Expected rows");
<span class="boring">}</span></code></pre>
<h3 id="data-results"><a class="header" href="#data-results">Data Results</a></h3>
<p>The primary outputs of the command (DataFrames, computed values). These are accessed via <code>data_get()</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let df = cmd_results
    .data_get(&amp;source.with_segment("data"))
    .and_then(|r| r.as_tabular());
<span class="boring">}</span></code></pre>
<p>Each command’s documentation lists which results are meta vs. data.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="filecommand"><a class="header" href="#filecommand">FileCommand</a></h1>
<p><code>FileCommand</code> loads data files from disk into the tabular store. It supports CSV, JSON, and Parquet formats.</p>
<h2 id="when-to-use"><a class="header" href="#when-to-use">When to Use</a></h2>
<p>Use <code>FileCommand</code> when you need to:</p>
<ul>
<li>Load one or more data files into a pipeline</li>
<li>Ingest data in different formats (CSV, JSON, Parquet)</li>
<li>Make tabular data available for SQL queries or aggregations</li>
</ul>
<h2 id="attributes"><a class="header" href="#attributes">Attributes</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Attribute</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>files</code></td><td>Array of objects</td><td>Yes</td><td>Array of file specifications to load</td></tr>
</tbody>
</table>
</div>
<h3 id="file-object-fields"><a class="header" href="#file-object-fields">File Object Fields</a></h3>
<p>Each object in the <code>files</code> array has the following fields:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>name</code></td><td>String</td><td>Yes</td><td>Identifier for this file in the tabular store</td></tr>
<tr><td><code>file</code></td><td>String</td><td>Yes</td><td>Path to the file (supports Tera substitution)</td></tr>
<tr><td><code>format</code></td><td>String</td><td>Yes</td><td>File format: <code>csv</code>, <code>json</code>, or <code>parquet</code> (supports Tera substitution)</td></tr>
</tbody>
</table>
</div>
<h2 id="results"><a class="header" href="#results">Results</a></h2>
<h3 id="meta-results-1"><a class="header" href="#meta-results-1">Meta Results</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>count</code></td><td>Number</td><td>Total number of files loaded</td></tr>
<tr><td><code>total_rows</code></td><td>Number</td><td>Sum of rows across all loaded files</td></tr>
<tr><td><code>total_size</code></td><td>Number</td><td>Sum of file sizes in bytes</td></tr>
</tbody>
</table>
</div>
<h3 id="data-results-per-file"><a class="header" href="#data-results-per-file">Data Results (Per File)</a></h3>
<p>For each file in the <code>files</code> array, the following results are produced under <code>{output_prefix}.{name}</code>:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>data</code></td><td>Tabular (DataFrame)</td><td>The loaded data</td></tr>
<tr><td><code>rows</code></td><td>Number</td><td>Row count for this file</td></tr>
<tr><td><code>size</code></td><td>Number</td><td>File size in bytes</td></tr>
<tr><td><code>columns</code></td><td>Array</td><td>Column names in the loaded data</td></tr>
</tbody>
</table>
</div>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<h3 id="loading-a-single-csv-file"><a class="header" href="#loading-a-single-csv-file">Loading a Single CSV File</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

let attrs = ObjectBuilder::new()
    .insert(
        "files",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "users")
                .insert("file", "/path/to/users.csv")
                .insert("format", "csv")
                .build_scalar(),
        ]),
    )
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("data"))
    .await?
    .add_command::&lt;FileCommand&gt;("load", &amp;attrs)
    .await?;

// After execution, the data is available at:
// - data.load.users.data      (the DataFrame)
// - data.load.users.rows      (row count)
// - data.load.users.columns   (column names)
<span class="boring">}</span></code></pre>
<h3 id="loading-multiple-formats"><a class="header" href="#loading-multiple-formats">Loading Multiple Formats</a></h3>
<p>Load CSV, JSON, and Parquet files in a single command:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "files",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "users")
                .insert("file", "fixtures/users.csv")
                .insert("format", "csv")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "events")
                .insert("file", "fixtures/events.json")
                .insert("format", "json")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "metrics")
                .insert("file", "fixtures/metrics.parquet")
                .insert("format", "parquet")
                .build_scalar(),
        ]),
    )
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("data"))
    .await?
    .add_command::&lt;FileCommand&gt;("load", &amp;attrs)
    .await?;
<span class="boring">}</span></code></pre>
<p>After execution:</p>
<ul>
<li><code>data.load.users.data</code> - DataFrame from users.csv</li>
<li><code>data.load.events.data</code> - DataFrame from events.json</li>
<li><code>data.load.metrics.data</code> - DataFrame from metrics.parquet</li>
<li><code>data.load.count</code> - 3 (number of files loaded)</li>
<li><code>data.load.total_rows</code> - Combined row count</li>
</ul>
<h3 id="using-tera-substitution-for-dynamic-paths"><a class="header" href="#using-tera-substitution-for-dynamic-paths">Using Tera Substitution for Dynamic Paths</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// First, set up a static namespace with configuration
pipeline
    .add_namespace(
        NamespaceBuilder::new("config")
            .static_ns()
            .insert("data_dir", ScalarValue::String("/var/data".to_string()))
            .insert("file_format", ScalarValue::String("csv".to_string())),
    )
    .await?;

// Then reference those values in FileCommand
let attrs = ObjectBuilder::new()
    .insert(
        "files",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "daily_report")
                .insert("file", "{{ config.data_dir }}/report.{{ config.file_format }}")
                .insert("format", "{{ config.file_format }}")
                .build_scalar(),
        ]),
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="accessing-results-1"><a class="header" href="#accessing-results-1">Accessing Results</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

let source = StorePath::from_segments(["data", "load"]);
let cmd_results = results.get_by_source(&amp;source).expect("Expected results");

// Access meta results
let file_count = cmd_results
    .meta_get(&amp;source.with_segment("count"))
    .expect("Expected count");
let total_rows = cmd_results
    .meta_get(&amp;source.with_segment("total_rows"))
    .expect("Expected total_rows");

println!("Loaded {} files with {} total rows", file_count, total_rows);

// Access per-file meta
let users_rows = cmd_results
    .meta_get(&amp;StorePath::from_dotted("data.load.users.rows"))
    .expect("Expected users rows");
<span class="boring">}</span></code></pre>
<h2 id="common-patterns-1"><a class="header" href="#common-patterns-1">Common Patterns</a></h2>
<h3 id="filecommand--sqlcommand"><a class="header" href="#filecommand--sqlcommand">FileCommand + SqlCommand</a></h3>
<p>Load data with <code>FileCommand</code>, then query it with <a href="#sqlcommand">SqlCommand</a>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Load
let file_attrs = ObjectBuilder::new()
    .insert("files", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "orders")
            .insert("file", "orders.csv")
            .insert("format", "csv")
            .build_scalar(),
    ]))
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("data"))
    .await?
    .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
    .await?;

// Query - reference the loaded data by store path
let query_attrs = ObjectBuilder::new()
    .insert("tables", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "orders")
            .insert("source", "data.load.orders.data")  // Store path reference
            .build_scalar(),
    ]))
    .insert("query", "SELECT * FROM orders WHERE status = 'completed'")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("query"))
    .await?
    .add_command::&lt;SqlCommand&gt;("completed", &amp;query_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h2 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h2>
<p><code>FileCommand</code> will return an error if:</p>
<ul>
<li>The file does not exist</li>
<li>The path points to a directory instead of a file</li>
<li>The file format is not one of <code>csv</code>, <code>json</code>, or <code>parquet</code></li>
<li>The file content cannot be parsed as the specified format</li>
</ul>
<h2 id="format-notes"><a class="header" href="#format-notes">Format Notes</a></h2>
<h3 id="csv"><a class="header" href="#csv">CSV</a></h3>
<ul>
<li>Assumes the first row contains headers</li>
<li>Uses default CSV parsing options from Polars</li>
</ul>
<h3 id="json"><a class="header" href="#json">JSON</a></h3>
<ul>
<li>Expects newline-delimited JSON (NDJSON) or JSON array format</li>
<li>Uses Polars’ <code>JsonReader</code></li>
</ul>
<h3 id="parquet"><a class="header" href="#parquet">Parquet</a></h3>
<ul>
<li>Reads standard Apache Parquet files</li>
<li>Efficient for large datasets with columnar storage</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="sqlcommand"><a class="header" href="#sqlcommand">SqlCommand</a></h1>
<p><code>SqlCommand</code> executes SQL queries against tabular data stored in the pipeline. It uses Polars’ SQL context to provide full SQL query capabilities on DataFrames.</p>
<h2 id="when-to-use-1"><a class="header" href="#when-to-use-1">When to Use</a></h2>
<p>Use <code>SqlCommand</code> when you need to:</p>
<ul>
<li>Filter rows based on conditions</li>
<li>Select specific columns</li>
<li>Join multiple tables together</li>
<li>Group and aggregate data</li>
<li>Transform data using SQL expressions</li>
<li>Order and limit results</li>
</ul>
<h2 id="attributes-1"><a class="header" href="#attributes-1">Attributes</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Attribute</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>tables</code></td><td>Array of objects</td><td>Yes</td><td>Table mappings from store paths to SQL table names</td></tr>
<tr><td><code>query</code></td><td>String</td><td>Yes</td><td>SQL query to execute (supports Tera substitution)</td></tr>
</tbody>
</table>
</div>
<h3 id="table-object-fields"><a class="header" href="#table-object-fields">Table Object Fields</a></h3>
<p>Each object in the <code>tables</code> array maps a store path to a table name for use in SQL:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>name</code></td><td>String</td><td>Yes</td><td>Table name to use in the SQL query</td></tr>
<tr><td><code>source</code></td><td>String</td><td>Yes</td><td>Store path to tabular data (e.g., <code>data.load.users.data</code>)</td></tr>
</tbody>
</table>
</div>
<h2 id="results-1"><a class="header" href="#results-1">Results</a></h2>
<h3 id="data-results-1"><a class="header" href="#data-results-1">Data Results</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>data</code></td><td>Tabular (DataFrame)</td><td>The query result</td></tr>
</tbody>
</table>
</div>
<h3 id="meta-results-2"><a class="header" href="#meta-results-2">Meta Results</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>rows</code></td><td>Number</td><td>Number of rows in the result</td></tr>
<tr><td><code>columns</code></td><td>Array</td><td>Column names in the result</td></tr>
</tbody>
</table>
</div>
<h2 id="examples-1"><a class="header" href="#examples-1">Examples</a></h2>
<h3 id="basic-query"><a class="header" href="#basic-query">Basic Query</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

// Assume data was loaded with FileCommand at data.load.users.data
let attrs = ObjectBuilder::new()
    .insert(
        "tables",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "users")
                .insert("source", "data.load.users.data")
                .build_scalar(),
        ]),
    )
    .insert("query", "SELECT * FROM users WHERE active = true")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("query"))
    .await?
    .add_command::&lt;SqlCommand&gt;("active_users", &amp;attrs)
    .await?;

// Result available at: query.active_users.data
<span class="boring">}</span></code></pre>
<h3 id="joining-multiple-tables"><a class="header" href="#joining-multiple-tables">Joining Multiple Tables</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "tables",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "users")
                .insert("source", "data.load.users.data")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "orders")
                .insert("source", "data.load.orders.data")
                .build_scalar(),
        ]),
    )
    .insert(
        "query",
        "SELECT u.name, u.email, o.order_id, o.total \
         FROM users u \
         INNER JOIN orders o ON u.id = o.user_id \
         ORDER BY o.total DESC",
    )
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("query"))
    .await?
    .add_command::&lt;SqlCommand&gt;("user_orders", &amp;attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="cross-join"><a class="header" href="#cross-join">Cross Join</a></h3>
<p>Combine every row from one table with every row from another:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "tables",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "users")
                .insert("source", "data.load.users.data")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "events")
                .insert("source", "data.load.events.data")
                .build_scalar(),
        ]),
    )
    .insert(
        "query",
        "SELECT u.name, u.email, e.type AS event_type, e.timestamp \
         FROM users u CROSS JOIN events e \
         ORDER BY u.name, e.timestamp",
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="dynamic-query-with-tera-substitution"><a class="header" href="#dynamic-query-with-tera-substitution">Dynamic Query with Tera Substitution</a></h3>
<p>Use Tera expressions to parameterize queries:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Static namespace with filter values
pipeline
    .add_namespace(
        NamespaceBuilder::new("inputs")
            .static_ns()
            .insert("status", ScalarValue::String("active".to_string()))
            .insert("min_age", ScalarValue::from(18)),
    )
    .await?;

// Query with Tera substitution
let attrs = ObjectBuilder::new()
    .insert(
        "tables",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "users")
                .insert("source", "data.load.users.data")
                .build_scalar(),
        ]),
    )
    .insert(
        "query",
        "SELECT * FROM users WHERE status = '{{ inputs.status }}' AND age &gt;= {{ inputs.min_age }}",
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="aggregation-in-sql"><a class="header" href="#aggregation-in-sql">Aggregation in SQL</a></h3>
<p>While <a href="#aggregatecommand">AggregateCommand</a> is available for simple aggregations, SQL can perform grouped aggregations:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "tables",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "orders")
                .insert("source", "data.load.orders.data")
                .build_scalar(),
        ]),
    )
    .insert(
        "query",
        "SELECT category, COUNT(*) as order_count, SUM(total) as revenue \
         FROM orders \
         GROUP BY category \
         ORDER BY revenue DESC",
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="accessing-results-2"><a class="header" href="#accessing-results-2">Accessing Results</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

let source = StorePath::from_segments(["query", "active_users"]);
let cmd_results = results.get_by_source(&amp;source).expect("Expected results");

// Access meta results
let row_count = cmd_results
    .meta_get(&amp;source.with_segment("rows"))
    .expect("Expected rows");
let columns = cmd_results
    .meta_get(&amp;source.with_segment("columns"))
    .expect("Expected columns");

println!("Query returned {} rows with columns: {}", row_count, columns);

// Access the DataFrame
let data_result = cmd_results
    .data_get(&amp;source.with_segment("data"))
    .expect("Expected data");
<span class="boring">}</span></code></pre>
<h2 id="common-patterns-2"><a class="header" href="#common-patterns-2">Common Patterns</a></h2>
<h3 id="chaining-sql-queries"><a class="header" href="#chaining-sql-queries">Chaining SQL Queries</a></h3>
<p>Use the output of one SQL query as input to another:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// First query: filter data
let filter_attrs = ObjectBuilder::new()
    .insert("tables", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "orders")
            .insert("source", "data.load.orders.data")
            .build_scalar(),
    ]))
    .insert("query", "SELECT * FROM orders WHERE status = 'completed'")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("step1"))
    .await?
    .add_command::&lt;SqlCommand&gt;("filtered", &amp;filter_attrs)
    .await?;

// Second query: aggregate the filtered data
let agg_attrs = ObjectBuilder::new()
    .insert("tables", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "orders")
            .insert("source", "step1.filtered.data")  // Reference previous result
            .build_scalar(),
    ]))
    .insert("query", "SELECT category, SUM(total) as revenue FROM orders GROUP BY category")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("step2"))
    .await?
    .add_command::&lt;SqlCommand&gt;("by_category", &amp;agg_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="sqlcommand--aggregatecommand"><a class="header" href="#sqlcommand--aggregatecommand">SqlCommand + AggregateCommand</a></h3>
<p>Query with SQL, then compute scalar statistics with AggregateCommand:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// SQL query
let query_attrs = ObjectBuilder::new()
    .insert("tables", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "products")
            .insert("source", "data.load.products.data")
            .build_scalar(),
    ]))
    .insert("query", "SELECT * FROM products WHERE in_stock = true")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("query"))
    .await?
    .add_command::&lt;SqlCommand&gt;("in_stock", &amp;query_attrs)
    .await?;

// Aggregate the query result
let agg_attrs = ObjectBuilder::new()
    .insert("source", "query.in_stock.data")
    .insert("aggregations", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "avg_price")
            .insert("column", "price")
            .insert("op", "mean")
            .build_scalar(),
    ]))
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("stats"))
    .await?
    .add_command::&lt;AggregateCommand&gt;("summary", &amp;agg_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h2 id="sql-dialect"><a class="header" href="#sql-dialect">SQL Dialect</a></h2>
<p><code>SqlCommand</code> uses Polars’ SQL context, which supports a subset of standard SQL:</p>
<ul>
<li><code>SELECT</code>, <code>FROM</code>, <code>WHERE</code>, <code>ORDER BY</code>, <code>LIMIT</code></li>
<li><code>JOIN</code> (INNER, LEFT, RIGHT, FULL, CROSS)</li>
<li><code>GROUP BY</code>, <code>HAVING</code></li>
<li>Common aggregate functions: <code>COUNT</code>, <code>SUM</code>, <code>AVG</code>, <code>MIN</code>, <code>MAX</code></li>
<li>String functions, date functions, and more</li>
</ul>
<p>Refer to the <a href="https://docs.pola.rs/user-guide/sql/intro/">Polars SQL documentation</a> for the complete list of supported features.</p>
<h2 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h2>
<p><code>SqlCommand</code> will return an error if:</p>
<ul>
<li>A table source store path does not exist</li>
<li>The SQL query syntax is invalid</li>
<li>A referenced column does not exist in the table</li>
<li>The query execution fails for any reason</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="aggregatecommand"><a class="header" href="#aggregatecommand">AggregateCommand</a></h1>
<p><code>AggregateCommand</code> computes scalar statistics from tabular data. It supports a variety of aggregation operations including count, sum, mean, min, max, median, and more.</p>
<h2 id="when-to-use-2"><a class="header" href="#when-to-use-2">When to Use</a></h2>
<p>Use <code>AggregateCommand</code> when you need to:</p>
<ul>
<li>Compute summary statistics from a DataFrame</li>
<li>Extract scalar values (counts, sums, averages) for use in templates or conditions</li>
<li>Calculate multiple aggregations in a single command</li>
<li>Get values like row count, unique counts, or null counts</li>
</ul>
<h2 id="attributes-2"><a class="header" href="#attributes-2">Attributes</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Attribute</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>source</code></td><td>String</td><td>Yes</td><td>Store path to tabular data (e.g., <code>data.load.products.data</code>)</td></tr>
<tr><td><code>aggregations</code></td><td>Array of objects</td><td>Yes</td><td>Array of aggregation specifications</td></tr>
</tbody>
</table>
</div>
<h3 id="aggregation-object-fields"><a class="header" href="#aggregation-object-fields">Aggregation Object Fields</a></h3>
<p>Each object in the <code>aggregations</code> array specifies one aggregation:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>name</code></td><td>String</td><td>Yes</td><td>Output scalar name for this aggregation</td></tr>
<tr><td><code>column</code></td><td>String</td><td>No</td><td>Column to aggregate (not required for <code>count</code>)</td></tr>
<tr><td><code>op</code></td><td>String</td><td>Yes</td><td>Aggregation operation to perform</td></tr>
</tbody>
</table>
</div>
<h3 id="supported-operations"><a class="header" href="#supported-operations">Supported Operations</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Operation</th><th>Aliases</th><th>Column Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>sum</code></td><td>-</td><td>Yes</td><td>Sum of values in the column</td></tr>
<tr><td><code>mean</code></td><td><code>avg</code>, <code>average</code></td><td>Yes</td><td>Arithmetic mean of values</td></tr>
<tr><td><code>min</code></td><td>-</td><td>Yes</td><td>Minimum value</td></tr>
<tr><td><code>max</code></td><td>-</td><td>Yes</td><td>Maximum value</td></tr>
<tr><td><code>count</code></td><td><code>len</code></td><td>No</td><td>Number of rows in the DataFrame</td></tr>
<tr><td><code>first</code></td><td>-</td><td>Yes</td><td>First value in the column</td></tr>
<tr><td><code>last</code></td><td>-</td><td>Yes</td><td>Last value in the column</td></tr>
<tr><td><code>std</code></td><td><code>stddev</code></td><td>Yes</td><td>Standard deviation</td></tr>
<tr><td><code>median</code></td><td>-</td><td>Yes</td><td>Median value</td></tr>
<tr><td><code>n_unique</code></td><td><code>nunique</code>, <code>distinct</code></td><td>Yes</td><td>Count of unique values</td></tr>
<tr><td><code>null_count</code></td><td><code>nulls</code></td><td>Yes</td><td>Count of null values in the column</td></tr>
</tbody>
</table>
</div>
<h2 id="results-2"><a class="header" href="#results-2">Results</a></h2>
<h3 id="data-results-per-aggregation"><a class="header" href="#data-results-per-aggregation">Data Results (Per Aggregation)</a></h3>
<p>For each aggregation in the <code>aggregations</code> array, a scalar result is produced:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>{name}</code></td><td>Scalar (Number)</td><td>The computed aggregation value</td></tr>
</tbody>
</table>
</div>
<p>The result path is <code>{output_prefix}.{name}</code>, where <code>{name}</code> is the <code>name</code> field from the aggregation object.</p>
<h2 id="examples-2"><a class="header" href="#examples-2">Examples</a></h2>
<h3 id="basic-aggregations"><a class="header" href="#basic-aggregations">Basic Aggregations</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

let attrs = ObjectBuilder::new()
    .insert("source", "data.load.products.data")
    .insert(
        "aggregations",
        ScalarValue::Array(vec![
            // Count doesn't need a column
            ObjectBuilder::new()
                .insert("name", "row_count")
                .insert("op", "count")
                .build_scalar(),
            // Sum requires a column
            ObjectBuilder::new()
                .insert("name", "total_price")
                .insert("column", "price")
                .insert("op", "sum")
                .build_scalar(),
            // Mean/average
            ObjectBuilder::new()
                .insert("name", "avg_price")
                .insert("column", "price")
                .insert("op", "mean")
                .build_scalar(),
        ]),
    )
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("stats"))
    .await?
    .add_command::&lt;AggregateCommand&gt;("summary", &amp;attrs)
    .await?;

// Results available at:
// - stats.summary.row_count
// - stats.summary.total_price
// - stats.summary.avg_price
<span class="boring">}</span></code></pre>
<h3 id="full-statistical-summary"><a class="header" href="#full-statistical-summary">Full Statistical Summary</a></h3>
<p>Compute comprehensive statistics for a dataset:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert("source", "data.load.products.data")
    .insert(
        "aggregations",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "row_count")
                .insert("op", "count")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "total_price")
                .insert("column", "price")
                .insert("op", "sum")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "avg_price")
                .insert("column", "price")
                .insert("op", "mean")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "max_quantity")
                .insert("column", "quantity")
                .insert("op", "max")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "min_quantity")
                .insert("column", "quantity")
                .insert("op", "min")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "median_price")
                .insert("column", "price")
                .insert("op", "median")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "price_stddev")
                .insert("column", "price")
                .insert("op", "std")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "unique_categories")
                .insert("column", "category")
                .insert("op", "n_unique")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "missing_descriptions")
                .insert("column", "description")
                .insert("op", "null_count")
                .build_scalar(),
        ]),
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="first-and-last-values"><a class="header" href="#first-and-last-values">First and Last Values</a></h3>
<p>Extract the first or last value from a column (useful for time-series data):</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert("source", "data.load.events.data")
    .insert(
        "aggregations",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "first_event")
                .insert("column", "event_type")
                .insert("op", "first")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "last_event")
                .insert("column", "event_type")
                .insert("op", "last")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "earliest_timestamp")
                .insert("column", "timestamp")
                .insert("op", "first")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "latest_timestamp")
                .insert("column", "timestamp")
                .insert("op", "last")
                .build_scalar(),
        ]),
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="accessing-results-3"><a class="header" href="#accessing-results-3">Accessing Results</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

let source = StorePath::from_segments(["stats", "products"]);
let cmd_results = results.get_by_source(&amp;source).expect("Expected results");

// Access aggregation results
let row_count = cmd_results
    .data_get(&amp;source.with_segment("row_count"))
    .and_then(|r| r.as_scalar())
    .expect("Expected row_count");

let avg_price = cmd_results
    .data_get(&amp;source.with_segment("avg_price"))
    .and_then(|r| r.as_scalar())
    .expect("Expected avg_price");

println!("Products: {} rows, average price: {}", row_count.1, avg_price.1);
<span class="boring">}</span></code></pre>
<h2 id="common-patterns-3"><a class="header" href="#common-patterns-3">Common Patterns</a></h2>
<h3 id="using-aggregates-in-templates"><a class="header" href="#using-aggregates-in-templates">Using Aggregates in Templates</a></h3>
<p>Aggregation results are stored in the scalar store and can be referenced in Tera templates:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// First: aggregate data
let agg_attrs = ObjectBuilder::new()
    .insert("source", "data.load.products.data")
    .insert("aggregations", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "total_count")
            .insert("op", "count")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "total_value")
            .insert("column", "price")
            .insert("op", "sum")
            .build_scalar(),
    ]))
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("stats"))
    .await?
    .add_command::&lt;AggregateCommand&gt;("summary", &amp;agg_attrs)
    .await?;

// Then: use in a template
let template_attrs = ObjectBuilder::new()
    .insert("templates", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "report")
            .insert("content", "Total products: {{ stats.summary.total_count }}\nTotal value: ${{ stats.summary.total_value }}")
            .build_scalar(),
    ]))
    .insert("render", "report")
    .insert("output", "/tmp/report.txt")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="using-aggregates-in-conditions"><a class="header" href="#using-aggregates-in-conditions">Using Aggregates in Conditions</a></h3>
<p>Branch logic based on aggregation results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Aggregate first
let agg_attrs = ObjectBuilder::new()
    .insert("source", "data.load.orders.data")
    .insert("aggregations", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "order_count")
            .insert("op", "count")
            .build_scalar(),
    ]))
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("metrics"))
    .await?
    .add_command::&lt;AggregateCommand&gt;("orders", &amp;agg_attrs)
    .await?;

// Condition based on aggregate
let condition_attrs = ObjectBuilder::new()
    .insert("branches", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "high_volume")
            .insert("if", "metrics.orders.order_count &gt; 1000")
            .insert("then", "High order volume detected")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "normal")
            .insert("if", "true")
            .insert("then", "Normal order volume")
            .build_scalar(),
    ]))
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="aggregating-sql-query-results"><a class="header" href="#aggregating-sql-query-results">Aggregating SQL Query Results</a></h3>
<p>Chain with <a href="#sqlcommand">SqlCommand</a> to aggregate filtered data:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Query
let query_attrs = ObjectBuilder::new()
    .insert("tables", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "orders")
            .insert("source", "data.load.orders.data")
            .build_scalar(),
    ]))
    .insert("query", "SELECT * FROM orders WHERE status = 'completed'")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("query"))
    .await?
    .add_command::&lt;SqlCommand&gt;("completed", &amp;query_attrs)
    .await?;

// Aggregate the filtered results
let agg_attrs = ObjectBuilder::new()
    .insert("source", "query.completed.data")  // Reference SQL output
    .insert("aggregations", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "completed_count")
            .insert("op", "count")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "total_revenue")
            .insert("column", "total")
            .insert("op", "sum")
            .build_scalar(),
    ]))
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="error-handling-2"><a class="header" href="#error-handling-2">Error Handling</a></h2>
<p><code>AggregateCommand</code> will return an error if:</p>
<ul>
<li>The source store path does not exist</li>
<li>A specified column does not exist in the DataFrame</li>
<li>An operation that requires a column (anything except <code>count</code>) is missing the <code>column</code> field</li>
<li>The operation name is not recognized</li>
</ul>
<h2 id="type-handling"><a class="header" href="#type-handling">Type Handling</a></h2>
<ul>
<li>Numeric columns return appropriate numeric types (integer or float)</li>
<li><code>first</code> and <code>last</code> operations work on both numeric and string columns</li>
<li>Non-finite values (NaN, infinity) are converted to null</li>
<li>Integer results are preserved when possible (e.g., count, sum of integers)</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="conditioncommand"><a class="header" href="#conditioncommand">ConditionCommand</a></h1>
<p><code>ConditionCommand</code> evaluates Tera expressions to select between multiple branches. It provides if/then branching logic for pipelines, producing a result based on the first matching condition.</p>
<h2 id="when-to-use-3"><a class="header" href="#when-to-use-3">When to Use</a></h2>
<p>Use <code>ConditionCommand</code> when you need to:</p>
<ul>
<li>Choose between different values based on runtime conditions</li>
<li>Implement feature flags or configuration-based branching</li>
<li>Generate different outputs based on data characteristics</li>
<li>Create conditional messages or labels</li>
</ul>
<h2 id="attributes-3"><a class="header" href="#attributes-3">Attributes</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Attribute</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>branches</code></td><td>Array of objects</td><td>Yes</td><td>Array of condition branches evaluated in order</td></tr>
<tr><td><code>default</code></td><td>String</td><td>No</td><td>Default value if no branch matches (supports Tera substitution)</td></tr>
</tbody>
</table>
</div>
<h3 id="branch-object-fields"><a class="header" href="#branch-object-fields">Branch Object Fields</a></h3>
<p>Each object in the <code>branches</code> array defines one condition:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>name</code></td><td>String</td><td>Yes</td><td>Unique identifier for this branch</td></tr>
<tr><td><code>if</code></td><td>String</td><td>Yes</td><td>Tera expression to evaluate as the condition</td></tr>
<tr><td><code>then</code></td><td>String</td><td>Yes</td><td>Value if condition is true (supports Tera substitution)</td></tr>
</tbody>
</table>
</div>
<h2 id="results-3"><a class="header" href="#results-3">Results</a></h2>
<h3 id="data-results-fixed"><a class="header" href="#data-results-fixed">Data Results (Fixed)</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>result</code></td><td>String</td><td>The value from the matched branch or default</td></tr>
<tr><td><code>matched</code></td><td>Boolean</td><td>Whether a branch condition matched (<code>false</code> if default was used)</td></tr>
<tr><td><code>branch_index</code></td><td>Number</td><td>Index of the matched branch (0-based), or -1 if default was used</td></tr>
</tbody>
</table>
</div>
<h3 id="data-results-per-branch"><a class="header" href="#data-results-per-branch">Data Results (Per Branch)</a></h3>
<p>For each branch in the <code>branches</code> array, an object is stored:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>{name}</code></td><td>Object</td><td>Contains <code>matched</code> (bool) and <code>value</code> (string) for this branch</td></tr>
</tbody>
</table>
</div>
<h2 id="condition-evaluation"><a class="header" href="#condition-evaluation">Condition Evaluation</a></h2>
<p>The <code>if</code> expression is wrapped in <code>{{ }}</code> and evaluated as a Tera expression. The result is considered truthy if it is:</p>
<ul>
<li>A non-empty string (except <code>"false"</code>, <code>"0"</code>, <code>"null"</code>, <code>"undefined"</code>)</li>
<li>A non-zero number</li>
<li>Boolean <code>true</code></li>
</ul>
<p>Branches are evaluated in order. The first truthy branch wins, and subsequent branches are not evaluated.</p>
<h2 id="examples-3"><a class="header" href="#examples-3">Examples</a></h2>
<h3 id="basic-conditional"><a class="header" href="#basic-conditional">Basic Conditional</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

// Set up inputs
pipeline
    .add_namespace(
        NamespaceBuilder::new("inputs")
            .static_ns()
            .insert("user_role", ScalarValue::String("admin".to_string())),
    )
    .await?;

let attrs = ObjectBuilder::new()
    .insert(
        "branches",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "admin_greeting")
                .insert("if", "inputs.user_role == 'admin'")
                .insert("then", "Welcome, Administrator!")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "user_greeting")
                .insert("if", "inputs.user_role == 'user'")
                .insert("then", "Welcome, User!")
                .build_scalar(),
        ]),
    )
    .insert("default", "Welcome, Guest!")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("greeting"))
    .await?
    .add_command::&lt;ConditionCommand&gt;("message", &amp;attrs)
    .await?;

// Result: "Welcome, Administrator!"
<span class="boring">}</span></code></pre>
<h3 id="feature-flag-pattern"><a class="header" href="#feature-flag-pattern">Feature Flag Pattern</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Static namespace with feature flags
pipeline
    .add_namespace(
        NamespaceBuilder::new("features")
            .static_ns()
            .insert("new_dashboard", ScalarValue::Bool(true))
            .insert("beta_api", ScalarValue::Bool(false)),
    )
    .await?;

let attrs = ObjectBuilder::new()
    .insert(
        "branches",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "new_dash")
                .insert("if", "features.new_dashboard")
                .insert("then", "/v2/dashboard")
                .build_scalar(),
        ]),
    )
    .insert("default", "/v1/dashboard")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("routing"))
    .await?
    .add_command::&lt;ConditionCommand&gt;("dashboard_path", &amp;attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="data-driven-conditions"><a class="header" href="#data-driven-conditions">Data-Driven Conditions</a></h3>
<p>Use values from earlier pipeline stages (like aggregations):</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Aggregate order data
let agg_attrs = ObjectBuilder::new()
    .insert("source", "data.load.orders.data")
    .insert("aggregations", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "order_count")
            .insert("op", "count")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "total_revenue")
            .insert("column", "total")
            .insert("op", "sum")
            .build_scalar(),
    ]))
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("metrics"))
    .await?
    .add_command::&lt;AggregateCommand&gt;("orders", &amp;agg_attrs)
    .await?;

// Branch based on metrics
let condition_attrs = ObjectBuilder::new()
    .insert(
        "branches",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "high_volume")
                .insert("if", "metrics.orders.order_count &gt; 1000")
                .insert("then", "HIGH_VOLUME")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "high_revenue")
                .insert("if", "metrics.orders.total_revenue &gt; 50000")
                .insert("then", "HIGH_REVENUE")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "normal")
                .insert("if", "true")  // Always matches as fallback
                .insert("then", "NORMAL")
                .build_scalar(),
        ]),
    )
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("classification"))
    .await?
    .add_command::&lt;ConditionCommand&gt;("tier", &amp;condition_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="using-tera-filters-and-functions"><a class="header" href="#using-tera-filters-and-functions">Using Tera Filters and Functions</a></h3>
<p>The <code>if</code> expression supports full Tera syntax:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "branches",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "long_name")
                .insert("if", "inputs.name | length &gt; 10")
                .insert("then", "Name is long")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "uppercase")
                .insert("if", "inputs.name == inputs.name | upper")
                .insert("then", "Name is all uppercase")
                .build_scalar(),
        ]),
    )
    .insert("default", "Name is normal")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="accessing-results-4"><a class="header" href="#accessing-results-4">Accessing Results</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

let source = StorePath::from_segments(["greeting", "message"]);
let cmd_results = results.get_by_source(&amp;source).expect("Expected results");

// Main result
let result = cmd_results
    .data_get(&amp;source.with_segment("result"))
    .and_then(|r| r.as_scalar())
    .expect("Expected result");
println!("Result: {}", result.1);

// Did any branch match?
let matched = cmd_results
    .data_get(&amp;source.with_segment("matched"))
    .and_then(|r| r.as_scalar())
    .expect("Expected matched");
println!("Matched: {}", matched.1);

// Which branch matched?
let index = cmd_results
    .data_get(&amp;source.with_segment("branch_index"))
    .and_then(|r| r.as_scalar())
    .expect("Expected branch_index");
println!("Branch index: {}", index.1);  // 0, 1, 2... or -1 for default
<span class="boring">}</span></code></pre>
<h2 id="common-patterns-4"><a class="header" href="#common-patterns-4">Common Patterns</a></h2>
<h3 id="conditional-with-when-attribute"><a class="header" href="#conditional-with-when-attribute">Conditional with <code>when</code> Attribute</a></h3>
<p>Combine <code>ConditionCommand</code> with the <code>when</code> attribute to skip the entire command:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert("when", "inputs.feature_enabled")  // Skip if false
    .insert(
        "branches",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "greeting")
                .insert("if", "true")
                .insert("then", "Hello, {{ inputs.user_name }}! Feature is active.")
                .build_scalar(),
        ]),
    )
    .insert("default", "Fallback message")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<p>When <code>when</code> is false:</p>
<ul>
<li>The command status is <code>"skipped"</code></li>
<li>No data results are produced</li>
<li><code>result</code>, <code>matched</code>, and <code>branch_index</code> are absent</li>
</ul>
<h3 id="multiple-independent-conditions"><a class="header" href="#multiple-independent-conditions">Multiple Independent Conditions</a></h3>
<p>Evaluate multiple conditions that don’t depend on each other:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "branches",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "is_admin")
                .insert("if", "inputs.role == 'admin'")
                .insert("then", "true")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "is_premium")
                .insert("if", "inputs.subscription == 'premium'")
                .insert("then", "true")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "has_access")
                .insert("if", "inputs.access_granted")
                .insert("then", "true")
                .build_scalar(),
        ]),
    )
    .build_hashmap();

// Access individual branch results:
// condition.check.is_admin.matched
// condition.check.is_premium.matched
// condition.check.has_access.matched
<span class="boring">}</span></code></pre>
<h3 id="cascading-ifelse"><a class="header" href="#cascading-ifelse">Cascading If/Else</a></h3>
<p>Use <code>true</code> as the final condition for an else clause:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "branches",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "premium")
                .insert("if", "metrics.score &gt; 90")
                .insert("then", "PREMIUM")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "standard")
                .insert("if", "metrics.score &gt; 50")
                .insert("then", "STANDARD")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "basic")
                .insert("if", "true")  // Else clause
                .insert("then", "BASIC")
                .build_scalar(),
        ]),
    )
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="using-results-in-templates"><a class="header" href="#using-results-in-templates">Using Results in Templates</a></h2>
<p>Condition results are stored in the scalar store and can be used in templates:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Condition command
let condition_attrs = ObjectBuilder::new()
    .insert("branches", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "status")
            .insert("if", "metrics.health &gt; 80")
            .insert("then", "healthy")
            .build_scalar(),
    ]))
    .insert("default", "degraded")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("check"))
    .await?
    .add_command::&lt;ConditionCommand&gt;("health", &amp;condition_attrs)
    .await?;

// Template using the result
let template_attrs = ObjectBuilder::new()
    .insert("templates", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "report")
            .insert("content", "System status: {{ check.health.result }}")
            .build_scalar(),
    ]))
    .insert("render", "report")
    .insert("output", "/tmp/status.txt")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="error-handling-3"><a class="header" href="#error-handling-3">Error Handling</a></h2>
<p><code>ConditionCommand</code> will return an error if:</p>
<ul>
<li>A branch is missing required fields (<code>name</code>, <code>if</code>, or <code>then</code>)</li>
<li>A Tera expression in <code>if</code> or <code>then</code> cannot be evaluated</li>
<li>Referenced variables in expressions do not exist in the scalar store</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="templatecommand"><a class="header" href="#templatecommand">TemplateCommand</a></h1>
<p><code>TemplateCommand</code> renders Tera templates and writes the output to a file. It supports template inheritance, includes, and loading templates from files or globs.</p>
<h2 id="when-to-use-4"><a class="header" href="#when-to-use-4">When to Use</a></h2>
<p>Use <code>TemplateCommand</code> when you need to:</p>
<ul>
<li>Generate reports, configuration files, or other text output</li>
<li>Use template inheritance with base templates and blocks</li>
<li>Render dynamic content using data from the pipeline</li>
<li>Create multiple output files from templates</li>
</ul>
<h2 id="attributes-4"><a class="header" href="#attributes-4">Attributes</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Attribute</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>templates</code></td><td>Array of objects</td><td>No</td><td>Inline template definitions (can be combined with <code>template_glob</code>)</td></tr>
<tr><td><code>template_glob</code></td><td>String</td><td>No</td><td>Glob pattern to load templates from disk (e.g., <code>templates/**/*.tera</code>)</td></tr>
<tr><td><code>render</code></td><td>String</td><td>Yes</td><td>Name of the template to render (supports Tera substitution)</td></tr>
<tr><td><code>output</code></td><td>String</td><td>Yes</td><td>File path to write the rendered output (supports Tera substitution)</td></tr>
<tr><td><code>capture</code></td><td>Boolean</td><td>No</td><td>If <code>true</code>, store the rendered content in the <code>content</code> result (default: <code>false</code>)</td></tr>
</tbody>
</table>
</div>
<p>At least one of <code>templates</code> or <code>template_glob</code> must provide the template to render.</p>
<h3 id="template-object-fields"><a class="header" href="#template-object-fields">Template Object Fields</a></h3>
<p>Each object in the <code>templates</code> array defines one template:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Field</th><th>Type</th><th>Required</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>name</code></td><td>String</td><td>Yes</td><td>Name to register the template under</td></tr>
<tr><td><code>content</code></td><td>String</td><td>No</td><td>Raw template content (mutually exclusive with <code>file</code>)</td></tr>
<tr><td><code>file</code></td><td>String</td><td>No</td><td>Path to template file (mutually exclusive with <code>content</code>)</td></tr>
</tbody>
</table>
</div>
<p>You must specify either <code>content</code> or <code>file</code>, but not both.</p>
<h2 id="results-4"><a class="header" href="#results-4">Results</a></h2>
<h3 id="meta-results-3"><a class="header" href="#meta-results-3">Meta Results</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>line_count</code></td><td>Number</td><td>Number of lines in the rendered output</td></tr>
<tr><td><code>size</code></td><td>Number</td><td>Size in bytes of the rendered output</td></tr>
</tbody>
</table>
</div>
<h3 id="data-results-2"><a class="header" href="#data-results-2">Data Results</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Result</th><th>Type</th><th>Description</th></tr>
</thead>
<tbody>
<tr><td><code>content</code></td><td>String</td><td>The rendered content (only populated when <code>capture</code> is <code>true</code>, otherwise empty)</td></tr>
</tbody>
</table>
</div>
<h2 id="examples-4"><a class="header" href="#examples-4">Examples</a></h2>
<h3 id="simple-inline-template"><a class="header" href="#simple-inline-template">Simple Inline Template</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

// Set up data for the template
pipeline
    .add_namespace(
        NamespaceBuilder::new("inputs")
            .static_ns()
            .insert("title", ScalarValue::String("Monthly Report".to_string()))
            .insert("date", ScalarValue::String("2024-01-15".to_string())),
    )
    .await?;

let attrs = ObjectBuilder::new()
    .insert(
        "templates",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "report")
                .insert("content", "# {{ inputs.title }}\n\nGenerated on: {{ inputs.date }}")
                .build_scalar(),
        ]),
    )
    .insert("render", "report")
    .insert("output", "/tmp/report.md")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("generate"))
    .await?
    .add_command::&lt;TemplateCommand&gt;("report", &amp;attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="template-inheritance-with-glob-loading"><a class="header" href="#template-inheritance-with-glob-loading">Template Inheritance with Glob Loading</a></h3>
<p>Load templates from disk using a glob pattern:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Directory structure:
// templates/
//   base.tera       - {% block content %}{% endblock %}
//   header.tera     - Navigation HTML
//   page.tera       - {% extends "base.tera" %}{% block content %}...{% endblock %}

let attrs = ObjectBuilder::new()
    .insert("template_glob", "templates/**/*.tera")
    .insert("render", "page.tera")
    .insert("output", "/tmp/page.html")
    .insert("capture", true)
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("render"))
    .await?
    .add_command::&lt;TemplateCommand&gt;("page", &amp;attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="template-inheritance-with-inline-templates"><a class="header" href="#template-inheritance-with-inline-templates">Template Inheritance with Inline Templates</a></h3>
<p>Define a base template and a child template inline:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "templates",
        ScalarValue::Array(vec![
            // Base template with blocks
            ObjectBuilder::new()
                .insert("name", "base")
                .insert("content", r#"&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;&lt;title&gt;{% block title %}Default Title{% endblock %}&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
{% block content %}{% endblock %}
&lt;/body&gt;
&lt;/html&gt;"#)
                .build_scalar(),
            // Child template that extends base
            ObjectBuilder::new()
                .insert("name", "page")
                .insert("content", r#"{% extends "base" %}
{% block title %}{{ inputs.page_title }}{% endblock %}
{% block content %}
&lt;h1&gt;{{ inputs.page_title }}&lt;/h1&gt;
&lt;p&gt;{{ inputs.page_content }}&lt;/p&gt;
{% endblock %}"#)
                .build_scalar(),
        ]),
    )
    .insert("render", "page")
    .insert("output", "/tmp/page.html")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="loading-templates-from-files"><a class="header" href="#loading-templates-from-files">Loading Templates from Files</a></h3>
<p>Reference template files instead of inline content:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "templates",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "base")
                .insert("file", "templates/base.tera")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "page")
                .insert("file", "templates/page.tera")
                .build_scalar(),
        ]),
    )
    .insert("render", "page")
    .insert("output", "/tmp/output.html")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="using-pipeline-data-in-templates"><a class="header" href="#using-pipeline-data-in-templates">Using Pipeline Data in Templates</a></h3>
<p>Templates have access to all scalar values in the store:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Load and aggregate data
let agg_attrs = ObjectBuilder::new()
    .insert("source", "data.load.products.data")
    .insert("aggregations", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "total_count")
            .insert("op", "count")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "total_value")
            .insert("column", "price")
            .insert("op", "sum")
            .build_scalar(),
    ]))
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("stats"))
    .await?
    .add_command::&lt;AggregateCommand&gt;("summary", &amp;agg_attrs)
    .await?;

// Use aggregation results in template
let template_attrs = ObjectBuilder::new()
    .insert(
        "templates",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "summary")
                .insert("content", r#"Product Summary
===============
Total products: {{ stats.summary.total_count }}
Total value: ${{ stats.summary.total_value }}

{% if stats.summary.total_count &gt; 100 %}
Note: High product count!
{% endif %}"#)
                .build_scalar(),
        ]),
    )
    .insert("render", "summary")
    .insert("output", "/tmp/summary.txt")
    .insert("capture", true)
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="dynamic-output-path"><a class="header" href="#dynamic-output-path">Dynamic Output Path</a></h3>
<p>Use Tera substitution for the output path:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pipeline
    .add_namespace(
        NamespaceBuilder::new("config")
            .static_ns()
            .insert("output_dir", ScalarValue::String("/var/reports".to_string()))
            .insert("report_name", ScalarValue::String("monthly".to_string())),
    )
    .await?;

let attrs = ObjectBuilder::new()
    .insert("templates", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "report")
            .insert("content", "Report content here...")
            .build_scalar(),
    ]))
    .insert("render", "report")
    .insert("output", "{{ config.output_dir }}/{{ config.report_name }}.txt")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="accessing-results-5"><a class="header" href="#accessing-results-5">Accessing Results</a></h2>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

let source = StorePath::from_segments(["render", "page"]);
let cmd_results = results.get_by_source(&amp;source).expect("Expected results");

// Meta results
let size = cmd_results
    .meta_get(&amp;source.with_segment("size"))
    .expect("Expected size");
let lines = cmd_results
    .meta_get(&amp;source.with_segment("line_count"))
    .expect("Expected line_count");

println!("Rendered {} bytes, {} lines", size, lines);

// Content (only if capture=true)
if let Some(content) = cmd_results
    .data_get(&amp;source.with_segment("content"))
    .and_then(|r| r.as_scalar())
{
    println!("Content: {}", content.1);
}
<span class="boring">}</span></code></pre>
<h2 id="common-patterns-5"><a class="header" href="#common-patterns-5">Common Patterns</a></h2>
<h3 id="combining-glob-and-inline-templates"><a class="header" href="#combining-glob-and-inline-templates">Combining Glob and Inline Templates</a></h3>
<p>Load base templates from disk, add custom templates inline:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert("template_glob", "templates/**/*.tera")  // Load from disk
    .insert(
        "templates",
        ScalarValue::Array(vec![
            // Add or override templates
            ObjectBuilder::new()
                .insert("name", "custom_page")
                .insert("content", r#"{% extends "base.tera" %}
{% block content %}Custom content here{% endblock %}"#)
                .build_scalar(),
        ]),
    )
    .insert("render", "custom_page")
    .insert("output", "/tmp/custom.html")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="iterating-over-data-with-tera"><a class="header" href="#iterating-over-data-with-tera">Iterating Over Data with Tera</a></h3>
<p>Use Tera’s for loop to iterate over arrays:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pipeline
    .add_namespace(
        NamespaceBuilder::new("inputs")
            .static_ns()
            .insert(
                "items",
                ScalarValue::Array(vec![
                    ObjectBuilder::new()
                        .insert("name", "Item 1")
                        .insert("price", 10.0)
                        .build_scalar(),
                    ObjectBuilder::new()
                        .insert("name", "Item 2")
                        .insert("price", 20.0)
                        .build_scalar(),
                ]),
            ),
    )
    .await?;

let attrs = ObjectBuilder::new()
    .insert("templates", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "list")
            .insert("content", r#"Items:
{% for item in inputs.items %}
- {{ item.name }}: ${{ item.price }}
{% endfor %}"#)
            .build_scalar(),
    ]))
    .insert("render", "list")
    .insert("output", "/tmp/items.txt")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="using-tera-includes"><a class="header" href="#using-tera-includes">Using Tera Includes</a></h3>
<p>Include templates within other templates:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let attrs = ObjectBuilder::new()
    .insert(
        "templates",
        ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "header")
                .insert("content", "&lt;header&gt;{{ inputs.site_name }}&lt;/header&gt;")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "footer")
                .insert("content", "&lt;footer&gt;Copyright 2024&lt;/footer&gt;")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "page")
                .insert("content", r#"{% include "header" %}
&lt;main&gt;Page content&lt;/main&gt;
{% include "footer" %}"#)
                .build_scalar(),
        ]),
    )
    .insert("render", "page")
    .insert("output", "/tmp/page.html")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h3 id="using-condition-results-in-templates"><a class="header" href="#using-condition-results-in-templates">Using Condition Results in Templates</a></h3>
<p>Reference <a href="#conditioncommand">ConditionCommand</a> results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Condition first
let condition_attrs = ObjectBuilder::new()
    .insert("branches", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "status")
            .insert("if", "metrics.health &gt; 80")
            .insert("then", "healthy")
            .build_scalar(),
    ]))
    .insert("default", "degraded")
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("check"))
    .await?
    .add_command::&lt;ConditionCommand&gt;("health", &amp;condition_attrs)
    .await?;

// Template using condition result
let template_attrs = ObjectBuilder::new()
    .insert("templates", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "status")
            .insert("content", r#"System Status: {{ check.health.result }}
{% if check.health.matched %}
(condition matched at branch {{ check.health.branch_index }})
{% else %}
(using default value)
{% endif %}"#)
            .build_scalar(),
    ]))
    .insert("render", "status")
    .insert("output", "/tmp/status.txt")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="tera-features"><a class="header" href="#tera-features">Tera Features</a></h2>
<p><code>TemplateCommand</code> uses the Tera templating engine, which supports:</p>
<ul>
<li>Variable substitution: <code>{{ variable }}</code></li>
<li>Conditionals: <code>{% if condition %}...{% endif %}</code></li>
<li>Loops: <code>{% for item in items %}...{% endfor %}</code></li>
<li>Template inheritance: <code>{% extends "base" %}</code> and <code>{% block name %}...{% endblock %}</code></li>
<li>Includes: <code>{% include "partial" %}</code></li>
<li>Filters: <code>{{ value | upper }}</code>, <code>{{ value | length }}</code>, etc.</li>
<li>Built-in functions and operators</li>
</ul>
<p>See the <a href="https://keats.github.io/tera/docs/">Tera documentation</a> for complete syntax reference.</p>
<h2 id="error-handling-4"><a class="header" href="#error-handling-4">Error Handling</a></h2>
<p><code>TemplateCommand</code> will return an error if:</p>
<ul>
<li>A template file specified in <code>file</code> does not exist</li>
<li>Both <code>content</code> and <code>file</code> are specified for a template (mutually exclusive)</li>
<li>Neither <code>content</code> nor <code>file</code> is specified for a template</li>
<li>The <code>template_glob</code> pattern is invalid or cannot be read</li>
<li>The template specified in <code>render</code> does not exist</li>
<li>Template syntax errors (unclosed blocks, invalid expressions)</li>
<li>Referenced variables do not exist in the scalar store</li>
<li>The output directory cannot be created</li>
<li>The output file cannot be written</li>
</ul>
<h2 id="directory-creation"><a class="header" href="#directory-creation">Directory Creation</a></h2>
<p><code>TemplateCommand</code> automatically creates parent directories for the output file if they do not exist.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="working-with-data"><a class="header" href="#working-with-data">Working with Data</a></h1>
<p>This section covers how data flows through Panopticon pipelines and the tools available for manipulating and accessing that data.</p>
<h2 id="data-flow-overview"><a class="header" href="#data-flow-overview">Data Flow Overview</a></h2>
<p>In Panopticon, data flows between commands through two parallel storage systems:</p>
<pre><code>+------------------+     +------------------+     +------------------+
|    Command A     |     |    Command B     |     |    Command C     |
+------------------+     +------------------+     +------------------+
         |                        |                        |
         v                        v                        v
+------------------------------------------------------------------------+
|                         ExecutionContext                               |
|  +----------------------------+  +----------------------------+        |
|  |       ScalarStore          |  |      TabularStore          |        |
|  |  (JSON-like values)        |  |  (Polars DataFrames)       |        |
|  +----------------------------+  +----------------------------+        |
+------------------------------------------------------------------------+
         ^                        ^                        ^
         |                        |                        |
   StorePath refs           StorePath refs           StorePath refs
</code></pre>
<h3 id="the-two-stores"><a class="header" href="#the-two-stores">The Two Stores</a></h3>
<p>Panopticon maintains two separate data stores during pipeline execution:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Store</th><th>Type Alias</th><th>Contents</th><th>Use Case</th></tr>
</thead>
<tbody>
<tr><td><strong>ScalarStore</strong></td><td><code>ScalarValue</code></td><td>JSON-compatible values (strings, numbers, booleans, arrays, objects)</td><td>Configuration, metadata, single values, template variables</td></tr>
<tr><td><strong>TabularStore</strong></td><td><code>TabularValue</code></td><td>Polars DataFrames</td><td>Structured data, CSV/JSON/Parquet files, SQL query results</td></tr>
</tbody>
</table>
</div>
<h3 id="storepath-the-universal-reference"><a class="header" href="#storepath-the-universal-reference">StorePath: The Universal Reference</a></h3>
<p>All data in both stores is addressed using <code>StorePath</code> - a dot-separated path that uniquely identifies values:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Creating paths
let path = StorePath::from_segments(["namespace", "command", "field"]);
let child = path.with_segment("subfield");    // namespace.command.field.subfield
let indexed = path.with_index(0);             // namespace.command.field.0
<span class="boring">}</span></code></pre>
<p>StorePaths serve as:</p>
<ul>
<li><strong>Storage keys</strong>: Where commands write their outputs</li>
<li><strong>Dependency references</strong>: How commands declare what data they need</li>
<li><strong>Template variables</strong>: Accessed via <code>{{ namespace.command.field }}</code> syntax</li>
<li><strong>Result accessors</strong>: How you retrieve data after pipeline execution</li>
</ul>
<h2 id="data-flow-example"><a class="header" href="#data-flow-example">Data Flow Example</a></h2>
<p>Consider a pipeline that loads a CSV file and performs aggregations:</p>
<pre><code>Pipeline Definition:
====================

Namespace: data                    Namespace: stats
+------------------+              +------------------+
| FileCommand      |              | AggregateCommand |
| name: "load"     | -----------&gt; | source: "data.   |
|                  |              |   load.products. |
|                  |              |   data"          |
+------------------+              +------------------+

Data Flow:
==========

1. FileCommand executes:
   - Reads products.csv
   - Stores DataFrame at: data.load.products.data
   - Stores row count at: data.load.products.row_count

2. AggregateCommand executes:
   - Retrieves DataFrame from: data.load.products.data
   - Computes aggregations
   - Stores results at: stats.products.*
</code></pre>
<h2 id="chapter-overview"><a class="header" href="#chapter-overview">Chapter Overview</a></h2>
<p>This section contains three detailed chapters:</p>
<h3 id="store-paths-1"><a class="header" href="#store-paths-1"><a href="#store-paths-2">Store Paths</a></a></h3>
<p>Learn the <code>StorePath</code> API for creating, manipulating, and navigating data paths:</p>
<ul>
<li><code>from_segments()</code> - Build paths from components</li>
<li><code>with_segment()</code> - Extend paths with new segments</li>
<li><code>with_index()</code> - Add numeric indices for iteration</li>
</ul>
<h3 id="tera-templating"><a class="header" href="#tera-templating"><a href="#tera-templating-1">Tera Templating</a></a></h3>
<p>Master the Tera templating syntax used throughout Panopticon:</p>
<ul>
<li>Variable interpolation with <code>{{ path.to.value }}</code></li>
<li>Filters for transforming values</li>
<li>Control structures for conditional content</li>
<li>Template inheritance for complex outputs</li>
</ul>
<h3 id="polars-dataframes"><a class="header" href="#polars-dataframes"><a href="#polars-dataframes-1">Polars DataFrames</a></a></h3>
<p>Work with tabular data using Polars:</p>
<ul>
<li>Understanding <code>TabularValue</code> (the DataFrame type alias)</li>
<li>Accessing DataFrame results from the <code>TabularStore</code></li>
<li>Export formats: CSV, JSON, Parquet</li>
</ul>
<h2 id="quick-reference"><a class="header" href="#quick-reference">Quick Reference</a></h2>
<h3 id="accessing-data-during-execution"><a class="header" href="#accessing-data-during-execution">Accessing Data During Execution</a></h3>
<p>Commands receive an <code>ExecutionContext</code> that provides access to both stores:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In a command's execute method:
async fn execute(&amp;self, ctx: &amp;ExecutionContext, source: &amp;StorePath) -&gt; Result&lt;()&gt; {
    // Read scalar values
    let value = ctx.scalar().get(&amp;some_path).await?;

    // Read tabular values
    let df = ctx.tabular().get(&amp;some_path).await?;

    // Template substitution (uses ScalarStore)
    let rendered = ctx.substitute("Hello, {{ user.name }}!").await?;

    // Write results
    ctx.scalar().insert(&amp;source.with_segment("output"), my_value).await?;
    ctx.tabular().insert(&amp;source.with_segment("data"), my_df).await?;

    Ok(())
}
<span class="boring">}</span></code></pre>
<h3 id="accessing-data-after-execution"><a class="header" href="#accessing-data-after-execution">Accessing Data After Execution</a></h3>
<p>After a pipeline completes, use <code>ResultStore</code> to access outputs:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

// Get results for a specific command
let source = StorePath::from_segments(["namespace", "command"]);
if let Some(cmd_results) = results.get_by_source(&amp;source) {
    // Access scalar results
    if let Some(value) = cmd_results.data_get(&amp;source.with_segment("field")) {
        if let Some((ty, scalar)) = value.as_scalar() {
            println!("Scalar: {:?} = {}", ty, scalar);
        }
    }

    // Access tabular results (exported to disk)
    if let Some(value) = cmd_results.data_get(&amp;source.with_segment("data")) {
        if let Some((path, format, rows, cols)) = value.as_tabular() {
            println!("Table: {} ({} rows x {} cols)", path.display(), rows, cols);
        }
    }
}
<span class="boring">}</span></code></pre>
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>Continue to <a href="#store-paths-2">Store Paths</a> to learn the details of the <code>StorePath</code> API.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="store-paths-2"><a class="header" href="#store-paths-2">Store Paths</a></h1>
<p><code>StorePath</code> is the fundamental addressing mechanism in Panopticon. Every piece of data - whether scalar values or tabular DataFrames - is stored and retrieved using a <code>StorePath</code>.</p>
<h2 id="what-is-a-storepath"><a class="header" href="#what-is-a-storepath">What is a StorePath?</a></h2>
<p>A <code>StorePath</code> is a sequence of string segments that form a hierarchical path, similar to filesystem paths but using dots as separators:</p>
<pre><code>namespace.command.field.subfield
    ^        ^      ^      ^
    |        |      |      +-- Nested field
    |        |      +--------- Result field
    |        +---------------- Command name
    +------------------------- Namespace name
</code></pre>
<p>The path <code>data.load.products.row_count</code> represents:</p>
<ul>
<li>Namespace: <code>data</code></li>
<li>Command: <code>load</code></li>
<li>Field: <code>products</code></li>
<li>Subfield: <code>row_count</code></li>
</ul>
<h2 id="creating-storepaths"><a class="header" href="#creating-storepaths">Creating StorePaths</a></h2>
<h3 id="from_segments"><a class="header" href="#from_segments">from_segments()</a></h3>
<p>Build a <code>StorePath</code> from an iterator of segments:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

// From a slice of string literals
let path = StorePath::from_segments(["namespace", "command", "field"]);
assert_eq!(path.to_dotted(), "namespace.command.field");

// From a Vec
let segments = vec!["data", "load", "products"];
let path = StorePath::from_segments(segments);
assert_eq!(path.to_dotted(), "data.load.products");

// From any iterator of Into&lt;String&gt;
let path = StorePath::from_segments(["a", "b", "c"].into_iter());
<span class="boring">}</span></code></pre>
<h3 id="from_dotted"><a class="header" href="#from_dotted">from_dotted()</a></h3>
<p>Parse a dotted string into a <code>StorePath</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let path = StorePath::from_dotted("config.regions.us-east");
assert_eq!(path.segments(), &amp;["config", "regions", "us-east"]);
<span class="boring">}</span></code></pre>
<h2 id="extending-storepaths"><a class="header" href="#extending-storepaths">Extending StorePaths</a></h2>
<p>StorePaths are immutable by default. Extension methods return new paths:</p>
<h3 id="with_segment"><a class="header" href="#with_segment">with_segment()</a></h3>
<p>Add a named segment to create a child path:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let base = StorePath::from_segments(["namespace", "command"]);

// Add a field
let field = base.with_segment("output");
assert_eq!(field.to_dotted(), "namespace.command.output");

// Chain multiple segments
let nested = base
    .with_segment("results")
    .with_segment("summary");
assert_eq!(nested.to_dotted(), "namespace.command.results.summary");
<span class="boring">}</span></code></pre>
<h3 id="with_index"><a class="header" href="#with_index">with_index()</a></h3>
<p>Add a numeric index segment (useful for iteration):</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let base = StorePath::from_segments(["classify", "region"]);

// First iteration
let iter0 = base.with_index(0);
assert_eq!(iter0.to_dotted(), "classify.region.0");

// Access a field within an iteration
let result = iter0.with_segment("result");
assert_eq!(result.to_dotted(), "classify.region.0.result");
<span class="boring">}</span></code></pre>
<h3 id="add_segment-mutable"><a class="header" href="#add_segment-mutable">add_segment() (Mutable)</a></h3>
<p>Mutate a path in place:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut path = StorePath::from_segments(["namespace"]);
path.add_segment("command");
path.add_segment("field");
assert_eq!(path.to_dotted(), "namespace.command.field");
<span class="boring">}</span></code></pre>
<h2 id="inspecting-storepaths"><a class="header" href="#inspecting-storepaths">Inspecting StorePaths</a></h2>
<h3 id="segments"><a class="header" href="#segments">segments()</a></h3>
<p>Get the path segments as a slice:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let path = StorePath::from_segments(["a", "b", "c"]);
assert_eq!(path.segments(), &amp;["a", "b", "c"]);
<span class="boring">}</span></code></pre>
<h3 id="namespace"><a class="header" href="#namespace">namespace()</a></h3>
<p>Get the first segment (typically the namespace name):</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let path = StorePath::from_segments(["data", "load", "file"]);
assert_eq!(path.namespace(), Some(&amp;"data".to_string()));

let empty = StorePath::default();
assert_eq!(empty.namespace(), None);
<span class="boring">}</span></code></pre>
<h3 id="to_dotted"><a class="header" href="#to_dotted">to_dotted()</a></h3>
<p>Convert to a dot-separated string:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let path = StorePath::from_segments(["config", "database", "host"]);
assert_eq!(path.to_dotted(), "config.database.host");
<span class="boring">}</span></code></pre>
<h3 id="starts_with"><a class="header" href="#starts_with">starts_with()</a></h3>
<p>Check if a path is a prefix of another:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let parent = StorePath::from_segments(["data", "load"]);
let child = StorePath::from_segments(["data", "load", "products", "data"]);
let other = StorePath::from_segments(["stats", "aggregate"]);

assert!(child.starts_with(&amp;parent));
assert!(!other.starts_with(&amp;parent));
<span class="boring">}</span></code></pre>
<h3 id="contains"><a class="header" href="#contains">contains()</a></h3>
<p>Check if any segment matches a value:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let path = StorePath::from_segments(["data", "load", "products"]);
assert!(path.contains("load"));
assert!(!path.contains("stats"));
<span class="boring">}</span></code></pre>
<h2 id="practical-examples"><a class="header" href="#practical-examples">Practical Examples</a></h2>
<h3 id="example-iterating-over-object-keys"><a class="header" href="#example-iterating-over-object-keys">Example: Iterating Over Object Keys</a></h3>
<p>This example from <code>iterate_object_keys.rs</code> shows how StorePaths work with iterative namespaces:</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let mut pipeline = Pipeline::new();

    // Static namespace with region data
    pipeline.add_namespace(
        NamespaceBuilder::new("config")
            .static_ns()
            .insert("regions", ObjectBuilder::new()
                .insert("us-east", "Virginia")
                .insert("us-west", "Oregon")
                .insert("eu-west", "Ireland")
                .build_scalar()
            ),
    ).await?;

    // Iterative namespace that loops over region keys
    let mut handle = pipeline.add_namespace(
        NamespaceBuilder::new("classify")
            .iterative()
            .store_path(StorePath::from_segments(["config", "regions"]))
            .scalar_object_keys(None, false)
            .iter_var("region")
            .index_var("idx"),
    ).await?;

    // Add condition command for each iteration
    handle.add_command::&lt;ConditionCommand&gt;("region", &amp;condition_attrs).await?;

    // Execute pipeline
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;

    // Access results per iteration using indexed StorePaths
    let mut idx = 0;
    loop {
        // Build path with iteration index
        let source = StorePath::from_segments(["classify", "region"])
            .with_index(idx);

        // Try to get results for this iteration
        let Some(cmd_results) = results.get_by_source(&amp;source) else {
            break; // No more iterations
        };

        // Access specific fields
        let result = cmd_results
            .data_get(&amp;source.with_segment("result"))
            .and_then(|r| r.as_scalar())
            .expect("Expected result");

        let matched = cmd_results
            .data_get(&amp;source.with_segment("matched"))
            .and_then(|r| r.as_scalar())
            .expect("Expected matched");

        println!("[{}] {} (matched: {})", idx, result.1, matched.1);
        idx += 1;
    }

    Ok(())
}</code></pre>
<h3 id="example-accessing-aggregation-results"><a class="header" href="#example-accessing-aggregation-results">Example: Accessing Aggregation Results</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

// After pipeline execution...
let results = completed.results(ResultSettings::default()).await?;

// Build path to the stats command
let stats_source = StorePath::from_segments(["stats", "products"]);

if let Some(cmd_results) = results.get_by_source(&amp;stats_source) {
    // Access individual aggregation results
    let fields = ["row_count", "total_price", "avg_price", "max_quantity"];

    for field in fields {
        let field_path = stats_source.with_segment(field);
        if let Some(value) = cmd_results.data_get(&amp;field_path) {
            if let Some((ty, scalar)) = value.as_scalar() {
                println!("{}: {} ({:?})", field, scalar, ty);
            }
        }
    }
}
<span class="boring">}</span></code></pre>
<h2 id="storepath-in-templates"><a class="header" href="#storepath-in-templates">StorePath in Templates</a></h2>
<p>StorePaths directly correspond to Tera template variables. The path <code>config.database.host</code> is accessed in templates as:</p>
<pre><code>{{ config.database.host }}
</code></pre>
<p>See <a href="#tera-templating-1">Tera Templating</a> for more details on template syntax.</p>
<h2 id="storepath-diagram"><a class="header" href="#storepath-diagram">StorePath Diagram</a></h2>
<pre><code>StorePath Structure:
====================

StorePath::from_segments(["data", "load", "products", "row_count"])
                            |      |        |           |
                            v      v        v           v
                         +------+------+---------+-----------+
    segments: Vec&lt;String&gt;|"data"|"load"|"products"|"row_count"|
                         +------+------+---------+-----------+
                            0      1        2           3

    to_dotted() -&gt; "data.load.products.row_count"
    namespace() -&gt; Some("data")
    segments()  -&gt; &amp;["data", "load", "products", "row_count"]


Path Operations:
================

    base = ["data", "load"]
              |
              +-- with_segment("file")    -&gt; ["data", "load", "file"]
              |
              +-- with_index(0)           -&gt; ["data", "load", "0"]
              |
              +-- with_segment("products")
                    |
                    +-- with_segment("data") -&gt; ["data", "load", "products", "data"]
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<ol>
<li>
<p><strong>Use meaningful segment names</strong>: Paths should be self-documenting</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good
StorePath::from_segments(["users", "fetch", "active_count"])

// Less clear
StorePath::from_segments(["u", "f", "ac"])
<span class="boring">}</span></code></pre>
</li>
<li>
<p><strong>Build paths incrementally</strong>: Use <code>with_segment()</code> to build on base paths</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let base = StorePath::from_segments(["namespace", "command"]);
let output = base.with_segment("output");
let data = base.with_segment("data");
<span class="boring">}</span></code></pre>
</li>
<li>
<p><strong>Use <code>with_index()</code> for iteration</strong>: Makes iteration patterns clear</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>for i in 0..count {
    let iter_path = base.with_index(i);
    // Process iteration...
}
<span class="boring">}</span></code></pre>
</li>
<li>
<p><strong>Store base paths as constants</strong>: Avoid typos in repeated path construction</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const DATA_NS: &amp;[&amp;str] = &amp;["data", "load"];
let base = StorePath::from_segments(DATA_NS.iter().copied());
<span class="boring">}</span></code></pre>
</li>
</ol>
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<p>Continue to <a href="#tera-templating-1">Tera Templating</a> to learn how StorePaths integrate with template syntax.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="tera-templating-1"><a class="header" href="#tera-templating-1">Tera Templating</a></h1>
<p>Panopticon uses <a href="https://tera.netlify.app/">Tera</a> as its templating engine. Tera provides a powerful, Jinja2-inspired syntax for variable interpolation, filters, and control structures.</p>
<h2 id="how-templates-connect-to-data"><a class="header" href="#how-templates-connect-to-data">How Templates Connect to Data</a></h2>
<p>The <code>ScalarStore</code> holds all scalar values (strings, numbers, booleans, arrays, objects) and serves as the template context. Any value stored via a <code>StorePath</code> becomes available in templates using dot notation:</p>
<pre><code>ScalarStore Contents:               Template Access:
=====================               ================

inputs.site_name = "My Site"    -&gt;  {{ inputs.site_name }}
inputs.page_title = "Home"      -&gt;  {{ inputs.page_title }}
config.debug = true             -&gt;  {{ config.debug }}
data.load.row_count = 42        -&gt;  {{ data.load.row_count }}
</code></pre>
<h2 id="basic-variable-interpolation"><a class="header" href="#basic-variable-interpolation">Basic Variable Interpolation</a></h2>
<h3 id="simple-values"><a class="header" href="#simple-values">Simple Values</a></h3>
<p>Access scalar values using double curly braces:</p>
<pre><code class="language-html">&lt;h1&gt;{{ inputs.site_name }}&lt;/h1&gt;
&lt;p&gt;Processing {{ data.load.row_count }} records&lt;/p&gt;
</code></pre>
<h3 id="nested-objects-1"><a class="header" href="#nested-objects-1">Nested Objects</a></h3>
<p>Navigate into nested structures with dot notation:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Stored as:
ObjectBuilder::new()
    .object("database", ObjectBuilder::new()
        .insert("host", "localhost")
        .insert("port", 5432))
    .build_scalar()
<span class="boring">}</span></code></pre>
<pre><code class="language-html">&lt;!-- Template --&gt;
Connecting to {{ config.database.host }}:{{ config.database.port }}
</code></pre>
<h3 id="array-access"><a class="header" href="#array-access">Array Access</a></h3>
<p>Access array elements by index:</p>
<pre><code class="language-html">First item: {{ items.0 }}
Third item: {{ items.2 }}
</code></pre>
<h2 id="filters"><a class="header" href="#filters">Filters</a></h2>
<p>Filters transform values using the pipe (<code>|</code>) syntax:</p>
<h3 id="built-in-filters"><a class="header" href="#built-in-filters">Built-in Filters</a></h3>
<pre><code class="language-html">&lt;!-- String manipulation --&gt;
{{ name | upper }}              &lt;!-- JOHN --&gt;
{{ name | lower }}              &lt;!-- john --&gt;
{{ name | capitalize }}         &lt;!-- John --&gt;
{{ name | title }}              &lt;!-- John Doe --&gt;
{{ text | trim }}               &lt;!-- removes whitespace --&gt;
{{ text | truncate(length=20) }}

&lt;!-- Number formatting --&gt;
{{ price | round }}             &lt;!-- 10 --&gt;
{{ price | round(precision=2) }}&lt;!-- 9.99 --&gt;

&lt;!-- Collections --&gt;
{{ items | length }}            &lt;!-- array length --&gt;
{{ items | first }}             &lt;!-- first element --&gt;
{{ items | last }}              &lt;!-- last element --&gt;
{{ items | reverse }}           &lt;!-- reversed array --&gt;
{{ items | join(sep=", ") }}    &lt;!-- comma-separated --&gt;

&lt;!-- Default values --&gt;
{{ maybe_null | default(value="N/A") }}

&lt;!-- JSON encoding --&gt;
{{ object | json_encode() }}
{{ object | json_encode(pretty=true) }}

&lt;!-- Escaping --&gt;
{{ html_content | safe }}       &lt;!-- no escaping --&gt;
{{ user_input | escape }}       &lt;!-- HTML escape --&gt;
</code></pre>
<h3 id="filter-chaining"><a class="header" href="#filter-chaining">Filter Chaining</a></h3>
<p>Chain multiple filters together:</p>
<pre><code class="language-html">{{ name | trim | upper | truncate(length=10) }}
</code></pre>
<h2 id="control-structures"><a class="header" href="#control-structures">Control Structures</a></h2>
<h3 id="conditionals"><a class="header" href="#conditionals">Conditionals</a></h3>
<pre><code class="language-html">{% if config.debug %}
    &lt;div class="debug-panel"&gt;Debug mode enabled&lt;/div&gt;
{% endif %}

{% if user.role == "admin" %}
    &lt;a href="/admin"&gt;Admin Panel&lt;/a&gt;
{% elif user.role == "editor" %}
    &lt;a href="/edit"&gt;Edit Content&lt;/a&gt;
{% else %}
    &lt;span&gt;Welcome, guest&lt;/span&gt;
{% endif %}
</code></pre>
<h3 id="loops"><a class="header" href="#loops">Loops</a></h3>
<p>Iterate over arrays:</p>
<pre><code class="language-html">&lt;ul&gt;
{% for item in inputs.nav_items %}
    &lt;li&gt;&lt;a href="{{ item.url }}"&gt;{{ item.label }}&lt;/a&gt;&lt;/li&gt;
{% endfor %}
&lt;/ul&gt;
</code></pre>
<p>Loop variables:</p>
<pre><code class="language-html">{% for item in items %}
    {{ loop.index }}      &lt;!-- 1-indexed position --&gt;
    {{ loop.index0 }}     &lt;!-- 0-indexed position --&gt;
    {{ loop.first }}      &lt;!-- true if first iteration --&gt;
    {{ loop.last }}       &lt;!-- true if last iteration --&gt;
{% endfor %}
</code></pre>
<p>Iterate over object key-value pairs:</p>
<pre><code class="language-html">{% for key, value in config.settings %}
    {{ key }}: {{ value }}
{% endfor %}
</code></pre>
<h2 id="template-inheritance"><a class="header" href="#template-inheritance">Template Inheritance</a></h2>
<p>Tera supports template inheritance for building complex layouts:</p>
<h3 id="base-template-basetera"><a class="header" href="#base-template-basetera">Base Template (base.tera)</a></h3>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;{% block title %}Default Title{% endblock %}&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
{% block header %}{% endblock %}
&lt;main&gt;
{% block content %}{% endblock %}
&lt;/main&gt;
&lt;footer&gt;
    &lt;p&gt;Generated by Panopticon&lt;/p&gt;
&lt;/footer&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="child-template-pagetera"><a class="header" href="#child-template-pagetera">Child Template (page.tera)</a></h3>
<pre><code class="language-html">{% extends "base.tera" %}

{% block title %}{{ inputs.page_title }} - {{ inputs.site_name }}{% endblock %}

{% block header %}
{% include "header.tera" %}
{% endblock %}

{% block content %}
&lt;article&gt;
    &lt;h2&gt;{{ inputs.page_title }}&lt;/h2&gt;
    &lt;p&gt;{{ inputs.page_content }}&lt;/p&gt;
&lt;/article&gt;
{% endblock %}
</code></pre>
<h3 id="include-template-headertera"><a class="header" href="#include-template-headertera">Include Template (header.tera)</a></h3>
<pre><code class="language-html">&lt;header&gt;
    &lt;h1&gt;{{ inputs.site_name }}&lt;/h1&gt;
    &lt;nav&gt;
        {% for item in inputs.nav_items %}
        &lt;a href="{{ item.url }}"&gt;{{ item.label }}&lt;/a&gt;
        {% endfor %}
    &lt;/nav&gt;
&lt;/header&gt;
</code></pre>
<h2 id="using-templates-in-panopticon"><a class="header" href="#using-templates-in-panopticon">Using Templates in Panopticon</a></h2>
<h3 id="templatecommand-1"><a class="header" href="#templatecommand-1">TemplateCommand</a></h3>
<p>The <code>TemplateCommand</code> renders Tera templates:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

let mut pipeline = Pipeline::new();

// Add input data
pipeline.add_namespace(
    NamespaceBuilder::new("inputs")
        .static_ns()
        .insert("site_name", ScalarValue::String("Panopticon Demo".into()))
        .insert("page_title", ScalarValue::String("Getting Started".into()))
        .insert("page_content", ScalarValue::String("Welcome!".into()))
        .insert("nav_items", ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("label", "Home")
                .insert("url", "/")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("label", "Docs")
                .insert("url", "/docs")
                .build_scalar(),
        ])),
).await?;

// Configure template command
let template_attrs = ObjectBuilder::new()
    .insert("template_glob", "/path/to/templates/**/*.tera")
    .insert("render", "page.tera")
    .insert("output", "/output/page.html")
    .insert("capture", true)  // Also store rendered content in ScalarStore
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("render"))
    .await?
    .add_command::&lt;TemplateCommand&gt;("page", &amp;template_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<h3 id="inline-template-substitution"><a class="header" href="#inline-template-substitution">Inline Template Substitution</a></h3>
<p>Use <code>ctx.substitute()</code> for inline template rendering:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In command execution
let greeting = ctx.substitute("Hello, {{ user.name }}!").await?;
<span class="boring">}</span></code></pre>
<h3 id="condition-expressions"><a class="header" href="#condition-expressions">Condition Expressions</a></h3>
<p>The <code>ConditionCommand</code> uses Tera expressions for branching:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let condition_attrs = ObjectBuilder::new()
    .insert("branches", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "is_us")
            .insert("if", "region is starting_with(\"us-\")")
            .insert("then", "Region {{ region }} is in the US")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "is_eu")
            .insert("if", "region is starting_with(\"eu-\")")
            .insert("then", "Region {{ region }} is in the EU")
            .build_scalar(),
    ]))
    .insert("default", "Region {{ region }} is in an unknown area")
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="tera-tests"><a class="header" href="#tera-tests">Tera Tests</a></h2>
<p>Tera “tests” check conditions on values (used with <code>is</code> keyword):</p>
<pre><code class="language-html">{% if value is defined %}...{% endif %}
{% if value is undefined %}...{% endif %}
{% if value is odd %}...{% endif %}
{% if value is even %}...{% endif %}
{% if text is containing("needle") %}...{% endif %}
{% if text is starting_with("prefix") %}...{% endif %}
{% if text is ending_with("suffix") %}...{% endif %}
{% if text is matching("regex") %}...{% endif %}
</code></pre>
<h2 id="data-flow-diagram"><a class="header" href="#data-flow-diagram">Data Flow Diagram</a></h2>
<pre><code>Template Rendering Flow:
========================

+-------------------+
|   ScalarStore     |
|                   |
| inputs.site_name  |
| inputs.page_title |
| inputs.nav_items  |
| config.debug      |
+--------+----------+
         |
         v
+-------------------+
|   Tera Context    |  &lt;- ScalarStore becomes the template context
+--------+----------+
         |
         v
+-------------------+
|  Template File    |
|                   |
| {{ inputs.xxx }}  |
| {% for item %}    |
| {% if config %}   |
+--------+----------+
         |
         v
+-------------------+
|  Rendered Output  |
|                   |
| &lt;h1&gt;My Site&lt;/h1&gt;  |
| &lt;p&gt;Welcome!&lt;/p&gt;   |
+-------------------+
</code></pre>
<h2 id="common-patterns-6"><a class="header" href="#common-patterns-6">Common Patterns</a></h2>
<h3 id="conditional-css-classes"><a class="header" href="#conditional-css-classes">Conditional CSS Classes</a></h3>
<pre><code class="language-html">&lt;div class="alert {% if level == "error" %}alert-danger{% elif level == "warning" %}alert-warning{% else %}alert-info{% endif %}"&gt;
    {{ message }}
&lt;/div&gt;
</code></pre>
<h3 id="building-urls-with-parameters"><a class="header" href="#building-urls-with-parameters">Building URLs with Parameters</a></h3>
<pre><code class="language-html">&lt;a href="/users/{{ user.id }}?tab={{ tab | default(value="overview") }}"&gt;
    View Profile
&lt;/a&gt;
</code></pre>
<h3 id="json-data-embedding"><a class="header" href="#json-data-embedding">JSON Data Embedding</a></h3>
<pre><code class="language-html">&lt;script&gt;
    const config = {{ config | json_encode(pretty=true) | safe }};
&lt;/script&gt;
</code></pre>
<h3 id="iteration-with-separators"><a class="header" href="#iteration-with-separators">Iteration with Separators</a></h3>
<pre><code class="language-html">{% for tag in tags %}{{ tag }}{% if not loop.last %}, {% endif %}{% endfor %}
</code></pre>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="common-errors"><a class="header" href="#common-errors">Common Errors</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Error</th><th>Cause</th><th>Solution</th></tr>
</thead>
<tbody>
<tr><td><code>Variable not found</code></td><td>Path doesn’t exist in ScalarStore</td><td>Check StorePath and ensure data is stored before template renders</td></tr>
<tr><td><code>Cannot iterate over</code></td><td>Value is not an array</td><td>Verify the value type with <code>{% if items is iterable %}</code></td></tr>
<tr><td><code>Filter not found</code></td><td>Typo in filter name</td><td>Check Tera documentation for correct filter names</td></tr>
</tbody>
</table>
</div>
<h3 id="debugging-tips"><a class="header" href="#debugging-tips">Debugging Tips</a></h3>
<ol>
<li>
<p><strong>Check available data</strong>: Use <code>{{ __tera_context }}</code> to dump all available variables (if enabled)</p>
</li>
<li>
<p><strong>Use default values</strong>: Prevent errors from missing data</p>
<pre><code class="language-html">{{ maybe_missing | default(value="fallback") }}
</code></pre>
</li>
<li>
<p><strong>Test variable existence</strong>:</p>
<pre><code class="language-html">{% if my_var is defined %}
    {{ my_var }}
{% else %}
    Variable not set
{% endif %}
</code></pre>
</li>
</ol>
<h2 id="reference-links"><a class="header" href="#reference-links">Reference Links</a></h2>
<ul>
<li><a href="https://tera.netlify.app/docs/">Tera Documentation</a></li>
<li><a href="https://tera.netlify.app/docs/#built-in-filters">Tera Built-in Filters</a></li>
<li><a href="https://tera.netlify.app/docs/#built-in-tests">Tera Built-in Tests</a></li>
</ul>
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<p>Continue to <a href="#polars-dataframes-1">Polars DataFrames</a> to learn about working with tabular data.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="polars-dataframes-1"><a class="header" href="#polars-dataframes-1">Polars DataFrames</a></h1>
<p>Panopticon uses <a href="https://pola.rs/">Polars</a> for tabular data operations. Polars is a high-performance DataFrame library written in Rust, providing excellent performance for data manipulation tasks.</p>
<h2 id="tabularvalue-and-tabularstore"><a class="header" href="#tabularvalue-and-tabularstore">TabularValue and TabularStore</a></h2>
<h3 id="type-definitions"><a class="header" href="#type-definitions">Type Definitions</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// TabularValue is a type alias for Polars DataFrame
pub type TabularValue = polars::prelude::DataFrame;

// TabularStore manages DataFrames during pipeline execution
pub struct TabularStore {
    store: Arc&lt;RwLock&lt;HashMap&lt;String, TabularValue&gt;&gt;&gt;,
}
<span class="boring">}</span></code></pre>
<h3 id="store-operations"><a class="header" href="#store-operations">Store Operations</a></h3>
<p>The <code>TabularStore</code> provides async methods for managing DataFrames:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Insert a DataFrame
ctx.tabular().insert(&amp;path, dataframe).await?;

// Retrieve a DataFrame
let df: Option&lt;TabularValue&gt; = ctx.tabular().get(&amp;path).await?;

// Remove a DataFrame
let removed: Option&lt;TabularValue&gt; = ctx.tabular().remove(&amp;path).await?;

// List all stored paths
let keys: Vec&lt;String&gt; = ctx.tabular().keys().await;
<span class="boring">}</span></code></pre>
<h2 id="loading-tabular-data"><a class="header" href="#loading-tabular-data">Loading Tabular Data</a></h2>
<h3 id="filecommand-1"><a class="header" href="#filecommand-1">FileCommand</a></h3>
<p>Load data from CSV, JSON, or Parquet files:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let file_attrs = ObjectBuilder::new()
    .insert("files", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "products")
            .insert("file", "/path/to/products.csv")
            .insert("format", "csv")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "orders")
            .insert("file", "/path/to/orders.parquet")
            .insert("format", "parquet")
            .build_scalar(),
    ]))
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("data"))
    .await?
    .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<p>After execution, DataFrames are stored at paths like:</p>
<ul>
<li><code>data.load.products.data</code> - The DataFrame</li>
<li><code>data.load.products.row_count</code> - Number of rows (scalar)</li>
<li><code>data.load.orders.data</code> - Another DataFrame</li>
</ul>
<h3 id="sqlcommand-1"><a class="header" href="#sqlcommand-1">SqlCommand</a></h3>
<p>Query data using SQL:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let sql_attrs = ObjectBuilder::new()
    .insert("query", "SELECT * FROM products WHERE price &gt; 100")
    .insert("sources", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "products")
            .insert("path", "data.load.products.data")
            .build_scalar(),
    ]))
    .build_hashmap();
<span class="boring">}</span></code></pre>
<h2 id="aggregating-data"><a class="header" href="#aggregating-data">Aggregating Data</a></h2>
<h3 id="aggregatecommand-1"><a class="header" href="#aggregatecommand-1">AggregateCommand</a></h3>
<p>Perform statistical aggregations on DataFrames:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let agg_attrs = ObjectBuilder::new()
    .insert("source", "data.load.products.data")
    .insert("aggregations", ScalarValue::Array(vec![
        ObjectBuilder::new()
            .insert("name", "row_count")
            .insert("op", "count")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "total_price")
            .insert("column", "price")
            .insert("op", "sum")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "avg_price")
            .insert("column", "price")
            .insert("op", "mean")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "max_quantity")
            .insert("column", "quantity")
            .insert("op", "max")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "min_quantity")
            .insert("column", "quantity")
            .insert("op", "min")
            .build_scalar(),
        ObjectBuilder::new()
            .insert("name", "median_price")
            .insert("column", "price")
            .insert("op", "median")
            .build_scalar(),
    ]))
    .build_hashmap();

pipeline
    .add_namespace(NamespaceBuilder::new("stats"))
    .await?
    .add_command::&lt;AggregateCommand&gt;("products", &amp;agg_attrs)
    .await?;
<span class="boring">}</span></code></pre>
<p>Supported aggregation operations:</p>
<ul>
<li><code>count</code> - Row count (no column required)</li>
<li><code>sum</code> - Sum of column values</li>
<li><code>mean</code> - Average of column values</li>
<li><code>min</code> - Minimum value</li>
<li><code>max</code> - Maximum value</li>
<li><code>median</code> - Median value</li>
</ul>
<h2 id="accessing-dataframe-results"><a class="header" href="#accessing-dataframe-results">Accessing DataFrame Results</a></h2>
<h3 id="during-execution"><a class="header" href="#during-execution">During Execution</a></h3>
<p>Commands can access DataFrames from the execution context:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn execute(&amp;self, ctx: &amp;ExecutionContext, source: &amp;StorePath) -&gt; Result&lt;()&gt; {
    // Get DataFrame from TabularStore
    let df_path = StorePath::from_segments(["data", "load", "products", "data"]);
    let df = ctx.tabular()
        .get(&amp;df_path)
        .await?
        .context("DataFrame not found")?;

    // Work with the DataFrame
    println!("Columns: {:?}", df.get_column_names());
    println!("Shape: {:?}", df.shape());

    Ok(())
}
<span class="boring">}</span></code></pre>
<h3 id="after-execution"><a class="header" href="#after-execution">After Execution</a></h3>
<p>The <code>ResultStore</code> provides access to both scalar and tabular results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

for cmd_results in results.iter() {
    println!("Source: {}", cmd_results.source().to_dotted());

    // Iterate over metadata
    for (path, value) in cmd_results.meta_iter() {
        println!("  [meta] {} = {}", path.to_dotted(), value);
    }

    // Iterate over data results
    for (path, value) in cmd_results.data_iter() {
        match value.as_scalar() {
            Some((ty, val)) =&gt; {
                println!("  [data] {} = {} ({:?})", path.to_dotted(), val, ty);
            }
            None =&gt; {
                // Tabular results are exported to disk
                let (file_path, format, rows, cols) =
                    value.as_tabular().expect("Expected tabular result");
                println!(
                    "  [data] {} =&gt; {} ({} rows x {} cols)",
                    path.to_dotted(),
                    file_path.display(),
                    rows,
                    cols
                );
            }
        }
    }
}
<span class="boring">}</span></code></pre>
<h2 id="export-formats"><a class="header" href="#export-formats">Export Formats</a></h2>
<p>DataFrames are automatically exported to disk when accessing results. Configure the format via <code>ResultSettings</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Export as CSV
let settings = ResultSettings::new()
    .with_format(TabularFormat::Csv)
    .with_output_path(PathBuf::from("/output/directory"));

// Export as JSON
let settings = ResultSettings::new()
    .with_format(TabularFormat::Json);

// Export as Parquet (default)
let settings = ResultSettings::new()
    .with_format(TabularFormat::Parquet);

let results = completed.results(settings).await?;
<span class="boring">}</span></code></pre>
<h3 id="tabularformat-options"><a class="header" href="#tabularformat-options">TabularFormat Options</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Format</th><th>Extension</th><th>Use Case</th></tr>
</thead>
<tbody>
<tr><td><code>TabularFormat::Csv</code></td><td><code>.csv</code></td><td>Human-readable, spreadsheet compatible</td></tr>
<tr><td><code>TabularFormat::Json</code></td><td><code>.json</code></td><td>Web applications, APIs</td></tr>
<tr><td><code>TabularFormat::Parquet</code></td><td><code>.parquet</code></td><td>Efficient storage, data pipelines</td></tr>
</tbody>
</table>
</div>
<h2 id="data-flow-diagram-1"><a class="header" href="#data-flow-diagram-1">Data Flow Diagram</a></h2>
<pre><code>Tabular Data Flow:
==================

+------------------+
|  Input Files     |
|  - products.csv  |
|  - orders.json   |
+--------+---------+
         |
         v
+------------------+
|   FileCommand    |
+--------+---------+
         |
         v
+------------------+
|  TabularStore    |
|                  |
| data.load.       |
|   products.data  |  &lt;-- DataFrame
|   orders.data    |  &lt;-- DataFrame
+--------+---------+
         |
    +----+----+
    |         |
    v         v
+-------+  +------------+
| SQL   |  | Aggregate  |
+---+---+  +-----+------+
    |            |
    v            v
+------------------+
|  TabularStore    |
| (updated)        |
+--------+---------+
         |
         v
+------------------+
|   ResultStore    |
+--------+---------+
         |
         v
+------------------+
|  Output Files    |
|  - .csv          |
|  - .json         |
|  - .parquet      |
+------------------+
</code></pre>
<h2 id="working-with-polars-directly"><a class="header" href="#working-with-polars-directly">Working with Polars Directly</a></h2>
<p>When building custom commands, you can use Polars DataFrame operations:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use polars::prelude::*;

// Create a DataFrame
let df = df!(
    "name" =&gt; &amp;["Alice", "Bob", "Charlie"],
    "age" =&gt; &amp;[30, 25, 35],
    "city" =&gt; &amp;["NYC", "LA", "Chicago"]
)?;

// Filter rows
let filtered = df.clone().lazy()
    .filter(col("age").gt(lit(28)))
    .collect()?;

// Select columns
let selected = df.clone().lazy()
    .select([col("name"), col("city")])
    .collect()?;

// Group and aggregate
let grouped = df.clone().lazy()
    .group_by([col("city")])
    .agg([
        col("age").mean().alias("avg_age"),
        col("name").count().alias("count"),
    ])
    .collect()?;

// Store in TabularStore
ctx.tabular().insert(&amp;source.with_segment("result"), filtered).await?;
<span class="boring">}</span></code></pre>
<h2 id="complete-example"><a class="header" href="#complete-example">Complete Example</a></h2>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;
use std::path::PathBuf;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let output_dir = tempfile::tempdir()?;
    let mut pipeline = Pipeline::new();

    // --- Load product data ---
    let file_attrs = ObjectBuilder::new()
        .insert("files", ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "products")
                .insert("file", "/path/to/products.csv")
                .insert("format", "csv")
                .build_scalar(),
        ]))
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("data"))
        .await?
        .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
        .await?;

    // --- Aggregate: compute statistics ---
    let agg_attrs = ObjectBuilder::new()
        .insert("source", "data.load.products.data")
        .insert("aggregations", ScalarValue::Array(vec![
            ObjectBuilder::new()
                .insert("name", "row_count")
                .insert("op", "count")
                .build_scalar(),
            ObjectBuilder::new()
                .insert("name", "total_price")
                .insert("column", "price")
                .insert("op", "sum")
                .build_scalar(),
        ]))
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("stats"))
        .await?
        .add_command::&lt;AggregateCommand&gt;("products", &amp;agg_attrs)
        .await?;

    // --- Execute with custom output path ---
    let completed = pipeline.compile().await?.execute().await?;
    let settings = ResultSettings::new()
        .with_output_path(output_dir.path().to_path_buf())
        .with_format(TabularFormat::Json);
    let results = completed.results(settings).await?;

    // --- Access results ---
    println!("=== Result Store ({} command(s)) ===\n", results.len());

    for cmd_results in results.iter() {
        println!("Source: {}", cmd_results.source().to_dotted());

        for (path, value) in cmd_results.data_iter() {
            match value.as_scalar() {
                Some((ty, val)) =&gt; {
                    println!("  {} = {} ({:?})", path.to_dotted(), val, ty);
                }
                None =&gt; {
                    let (file_path, fmt, rows, cols) =
                        value.as_tabular().expect("Expected tabular");
                    println!(
                        "  {} =&gt; {} ({} rows x {} cols)",
                        path.to_dotted(),
                        file_path.display(),
                        rows,
                        cols
                    );
                }
            }
        }
    }

    Ok(())
}</code></pre>
<h2 id="reference-links-1"><a class="header" href="#reference-links-1">Reference Links</a></h2>
<ul>
<li><a href="https://pola.rs/">Polars Documentation</a></li>
<li><a href="https://docs.rs/polars/latest/polars/">Polars Rust API</a></li>
<li><a href="https://pola-rs.github.io/polars/user-guide/">Polars User Guide</a></li>
</ul>
<h2 id="next-steps-4"><a class="header" href="#next-steps-4">Next Steps</a></h2>
<p>Explore <a href="#pipeline-patterns">Pipeline Patterns</a> to learn about iteration, conditional execution, and advanced pipeline techniques.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="pipeline-patterns"><a class="header" href="#pipeline-patterns">Pipeline Patterns</a></h1>
<p>This section covers common patterns and recipes for building effective Panopticon pipelines. Each pattern addresses a specific problem with a concrete solution you can adapt to your use case.</p>
<h2 id="pattern-overview"><a class="header" href="#pattern-overview">Pattern Overview</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Pattern</th><th>Problem</th><th>Solution</th></tr>
</thead>
<tbody>
<tr><td><a href="#iteration-1">Iteration</a></td><td>Process each item in a collection</td><td>Use iterative namespaces with <code>iter_var</code> and <code>index_var</code></td></tr>
<tr><td><a href="#conditional-execution-2">Conditional Execution</a></td><td>Skip commands based on runtime conditions</td><td>Use the <code>when</code> attribute with Tera expressions</td></tr>
<tr><td><a href="#pipeline-editing-1">Pipeline Editing</a></td><td>Add stages to an already-executed pipeline</td><td>Use <code>.edit()</code> to return to Draft state</td></tr>
<tr><td><a href="#result-access-1">Result Access</a></td><td>Retrieve and export pipeline outputs</td><td>Configure <code>ResultSettings</code> and iterate <code>ResultStore</code></td></tr>
</tbody>
</table>
</div>
<h2 id="when-to-use-these-patterns"><a class="header" href="#when-to-use-these-patterns">When to Use These Patterns</a></h2>
<h3 id="iteration"><a class="header" href="#iteration">Iteration</a></h3>
<p>Use iterative namespaces when you need to:</p>
<ul>
<li>Process each key in a configuration object</li>
<li>Apply the same operation to every item in an array</li>
<li>Loop over unique values in a DataFrame column</li>
<li>Split a string and handle each segment</li>
</ul>
<p><strong>Example scenario</strong>: You have a configuration object with region keys (<code>us-east</code>, <code>us-west</code>, <code>eu-west</code>) and need to run a classification command for each region.</p>
<h3 id="conditional-execution-1"><a class="header" href="#conditional-execution-1">Conditional Execution</a></h3>
<p>Use the <code>when</code> attribute when you need to:</p>
<ul>
<li>Feature-flag parts of your pipeline</li>
<li>Skip expensive operations when their inputs are empty</li>
<li>Create debug-only or production-only commands</li>
<li>Short-circuit processing based on earlier results</li>
</ul>
<p><strong>Example scenario</strong>: You have a feature flag in your configuration, and certain commands should only execute when that flag is enabled.</p>
<h3 id="pipeline-editing"><a class="header" href="#pipeline-editing">Pipeline Editing</a></h3>
<p>Use <code>.edit()</code> when you need to:</p>
<ul>
<li>Add follow-up analysis after initial exploration</li>
<li>Build pipelines incrementally based on intermediate results</li>
<li>Implement REPL-style workflows</li>
<li>Reuse expensive data loading across multiple analyses</li>
</ul>
<p><strong>Example scenario</strong>: You loaded a large dataset and ran an initial query. Now you want to add aggregation commands without re-loading the data.</p>
<h3 id="result-access"><a class="header" href="#result-access">Result Access</a></h3>
<p>Configure <code>ResultSettings</code> when you need to:</p>
<ul>
<li>Export tabular results to a specific directory</li>
<li>Choose output format (CSV, JSON, Parquet)</li>
<li>Exclude certain commands from result collection</li>
<li>Iterate over all results programmatically</li>
</ul>
<p><strong>Example scenario</strong>: After pipeline execution, you want to write all DataFrames to a temporary directory as Parquet files and print a summary of all computed metrics.</p>
<h2 id="combining-patterns"><a class="header" href="#combining-patterns">Combining Patterns</a></h2>
<p>These patterns compose naturally. A real-world pipeline might:</p>
<ol>
<li>Load data into a static namespace for configuration</li>
<li>Use an iterative namespace to process each configuration key</li>
<li>Apply <code>when</code> conditions to skip processing for disabled regions</li>
<li>Call <code>.edit()</code> to add aggregation after reviewing initial results</li>
<li>Export all results with custom <code>ResultSettings</code></li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pseudocode showing pattern composition
let mut pipeline = Pipeline::new();

// Static config (Pattern: static namespaces)
pipeline.add_namespace(NamespaceBuilder::new("config").static_ns()
    .insert("regions", regions_object)
    .insert("debug_mode", ScalarValue::Bool(false))
).await?;

// Iterative processing (Pattern: iteration)
let mut handle = pipeline.add_namespace(
    NamespaceBuilder::new("process")
        .iterative()
        .store_path(StorePath::from_segments(["config", "regions"]))
        .scalar_object_keys(None, false)
        .iter_var("region")
).await?;

// Conditional command (Pattern: when)
handle.add_command::&lt;ExpensiveCommand&gt;("analyze", &amp;ObjectBuilder::new()
    .insert("when", "config.debug_mode == false")  // Skip in debug mode
    .build_hashmap()
).await?;

// Execute first pass
let completed = pipeline.compile().await?.execute().await?;

// Add more analysis (Pattern: pipeline editing)
let mut pipeline = completed.edit();
pipeline.add_namespace(NamespaceBuilder::new("summary")).await?
    .add_command::&lt;AggregateCommand&gt;("totals", &amp;agg_attrs).await?;

// Re-execute and collect results (Pattern: result access)
let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(
    ResultSettings::new()
        .with_output_path(output_dir)
        .with_format(TabularFormat::Parquet)
).await?;
<span class="boring">}</span></code></pre>
<p>The following pages dive into each pattern with complete, runnable examples.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="iteration-1"><a class="header" href="#iteration-1">Iteration</a></h1>
<p><strong>Problem</strong>: You have a collection of items (object keys, array elements, or DataFrame column values) and need to run the same commands for each item.</p>
<p><strong>Solution</strong>: Create an iterative namespace that loops over the collection, exposing each item via <code>iter_var</code> and its position via <code>index_var</code>.</p>
<h2 id="how-iterative-namespaces-work"><a class="header" href="#how-iterative-namespaces-work">How Iterative Namespaces Work</a></h2>
<p>When you create an iterative namespace, Panopticon:</p>
<ol>
<li>Resolves the source collection from the data store</li>
<li>Executes all commands in the namespace once per item</li>
<li>Stores results with an index suffix (e.g., <code>classify.region[0]</code>, <code>classify.region[1]</code>)</li>
<li>Exposes the current item and index as template variables</li>
</ol>
<h2 id="iterator-types"><a class="header" href="#iterator-types">Iterator Types</a></h2>
<p>Panopticon supports four iterator types:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Type</th><th>Source</th><th>Iterates Over</th></tr>
</thead>
<tbody>
<tr><td><code>scalar_object_keys</code></td><td>JSON object</td><td>Keys of the object</td></tr>
<tr><td><code>scalar_array</code></td><td>JSON array</td><td>Elements of the array</td></tr>
<tr><td><code>string_split</code></td><td>String value</td><td>Segments split by delimiter</td></tr>
<tr><td><code>tabular_column</code></td><td>DataFrame column</td><td>Unique values in the column</td></tr>
</tbody>
</table>
</div>
<h2 id="basic-pattern-object-keys"><a class="header" href="#basic-pattern-object-keys">Basic Pattern: Object Keys</a></h2>
<p>The most common pattern is iterating over the keys of a configuration object.</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let mut pipeline = Pipeline::new();

    // Create a static namespace with an object to iterate over
    pipeline
        .add_namespace(
            NamespaceBuilder::new("config").static_ns().insert(
                "regions",
                ObjectBuilder::new()
                    .insert("us-east", "Virginia")
                    .insert("us-west", "Oregon")
                    .insert("eu-west", "Ireland")
                    .build_scalar(),
            ),
        )
        .await?;

    // Create an iterative namespace that loops over region keys
    let mut handle = pipeline
        .add_namespace(
            NamespaceBuilder::new("classify")
                .iterative()
                .store_path(StorePath::from_segments(["config", "regions"]))
                .scalar_object_keys(None, false)  // All keys, no exclusions
                .iter_var("region")               // Current key available as {{ region }}
                .index_var("idx"),                // Current index available as {{ idx }}
        )
        .await?;

    // This command runs once per region key
    let attrs = ObjectBuilder::new()
        .insert(
            "branches",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "is_us")
                    .insert("if", "region is starting_with(\"us-\")")
                    .insert("then", "Region {{ region }} is in the US")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "is_eu")
                    .insert("if", "region is starting_with(\"eu-\")")
                    .insert("then", "Region {{ region }} is in the EU")
                    .build_scalar(),
            ]),
        )
        .insert("default", "Region {{ region }} is in an unknown area")
        .build_hashmap();

    handle
        .add_command::&lt;ConditionCommand&gt;("check", &amp;attrs)
        .await?;

    // Execute the pipeline
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;

    // Access results by index
    for idx in 0.. {
        let source = StorePath::from_segments(["classify", "check"]).with_index(idx);
        let Some(cmd_results) = results.get_by_source(&amp;source) else {
            break;  // No more iterations
        };

        let result = cmd_results
            .data_get(&amp;source.with_segment("result"))
            .and_then(|r| r.as_scalar())
            .expect("Expected result");

        println!("[{}] {}", idx, result.1);
    }

    Ok(())
}</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>[0] Region us-east is in the US
[1] Region us-west is in the US
[2] Region eu-west is in the EU
</code></pre>
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<h3 id="iter_var-and-index_var"><a class="header" href="#iter_var-and-index_var">iter_var and index_var</a></h3>
<p>These methods define the template variable names used during iteration:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.iter_var("region")   // {{ region }} contains the current item
.index_var("idx")     // {{ idx }} contains 0, 1, 2, ...
<span class="boring">}</span></code></pre>
<p>If not specified, the defaults are:</p>
<ul>
<li><code>iter_var</code>: <code>"item"</code></li>
<li><code>index_var</code>: <code>"index"</code></li>
</ul>
<p>These variables are available in:</p>
<ul>
<li>Tera template expressions in command attributes</li>
<li>The <code>when</code> condition for conditional execution</li>
<li>Any attribute that supports Tera substitution</li>
</ul>
<h3 id="store_path"><a class="header" href="#store_path">store_path</a></h3>
<p>The <code>store_path</code> points to the collection in the scalar or tabular store:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.store_path(StorePath::from_segments(["config", "regions"]))
<span class="boring">}</span></code></pre>
<p>This path must exist when the pipeline executes. If it does not, execution fails with an error.</p>
<h3 id="result-indexing"><a class="header" href="#result-indexing">Result Indexing</a></h3>
<p>Iterative namespace results are indexed by iteration number. To access them:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Build the base path
let base = StorePath::from_segments(["namespace", "command"]);

// Access specific iteration
let iteration_0 = base.with_index(0);  // namespace.command[0]
let iteration_1 = base.with_index(1);  // namespace.command[1]

// Get results
let results_0 = results.get_by_source(&amp;iteration_0);
<span class="boring">}</span></code></pre>
<h2 id="filtering-object-keys"><a class="header" href="#filtering-object-keys">Filtering Object Keys</a></h2>
<p>You can filter which keys to iterate over:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Only iterate over specific keys
.scalar_object_keys(Some(vec!["us-east".to_string(), "eu-west".to_string()]), false)

// Exclude specific keys (iterate over all except these)
.scalar_object_keys(Some(vec!["us-west".to_string()]), true)

// Iterate over all keys
.scalar_object_keys(None, false)
<span class="boring">}</span></code></pre>
<h2 id="iterating-over-arrays"><a class="header" href="#iterating-over-arrays">Iterating Over Arrays</a></h2>
<p>To iterate over array elements instead of object keys:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pipeline
    .add_namespace(
        NamespaceBuilder::new("config").static_ns().insert(
            "items",
            ScalarValue::Array(vec![
                ScalarValue::String("apple".to_string()),
                ScalarValue::String("banana".to_string()),
                ScalarValue::String("cherry".to_string()),
            ]),
        ),
    )
    .await?;

let mut handle = pipeline
    .add_namespace(
        NamespaceBuilder::new("process")
            .iterative()
            .store_path(StorePath::from_segments(["config", "items"]))
            .scalar_array(None)        // All elements
            .iter_var("fruit"),
    )
    .await?;
<span class="boring">}</span></code></pre>
<p>With a range to limit iterations:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.scalar_array(Some((0, 2)))  // Only first two elements (indices 0 and 1)
<span class="boring">}</span></code></pre>
<h2 id="iterating-over-string-segments"><a class="header" href="#iterating-over-string-segments">Iterating Over String Segments</a></h2>
<p>Split a string and iterate over the parts:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pipeline
    .add_namespace(
        NamespaceBuilder::new("config").static_ns()
            .insert("path", ScalarValue::String("/usr/local/bin".to_string())),
    )
    .await?;

let mut handle = pipeline
    .add_namespace(
        NamespaceBuilder::new("segments")
            .iterative()
            .store_path(StorePath::from_segments(["config", "path"]))
            .string_split("/")         // Split on "/"
            .iter_var("segment"),
    )
    .await?;
<span class="boring">}</span></code></pre>
<h2 id="iterating-over-dataframe-columns"><a class="header" href="#iterating-over-dataframe-columns">Iterating Over DataFrame Columns</a></h2>
<p>Extract unique values from a DataFrame column:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Assuming data.load.users.data contains a DataFrame with a "department" column
let mut handle = pipeline
    .add_namespace(
        NamespaceBuilder::new("by_dept")
            .iterative()
            .store_path(StorePath::from_segments(["data", "load", "users", "data"]))
            .tabular_column("department", None)  // Unique values from "department"
            .iter_var("dept"),
    )
    .await?;
<span class="boring">}</span></code></pre>
<p>This iterates over the unique, non-null values in the specified column. Use a range to limit:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.tabular_column("department", Some((0, 5)))  // First 5 unique values
<span class="boring">}</span></code></pre>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<h3 id="use-descriptive-variable-names"><a class="header" href="#use-descriptive-variable-names">Use Descriptive Variable Names</a></h3>
<p>Choose <code>iter_var</code> names that reflect what you are iterating over:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: clear what we're iterating
.iter_var("region")
.iter_var("user_id")
.iter_var("filename")

// Avoid: generic names
.iter_var("item")
.iter_var("x")
<span class="boring">}</span></code></pre>
<h3 id="keep-iteration-counts-reasonable"><a class="header" href="#keep-iteration-counts-reasonable">Keep Iteration Counts Reasonable</a></h3>
<p>Each iteration creates separate command executions and results. For large collections, consider:</p>
<ul>
<li>Filtering with <code>scalar_object_keys(Some(keys), false)</code></li>
<li>Using ranges with <code>scalar_array(Some((start, end)))</code></li>
<li>Pre-filtering data with <code>SqlCommand</code> before iteration</li>
</ul>
<h3 id="access-results-systematically"><a class="header" href="#access-results-systematically">Access Results Systematically</a></h3>
<p>When iterating over results, use a loop that terminates when <code>get_by_source</code> returns <code>None</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut idx = 0;
loop {
    let source = StorePath::from_segments(["ns", "cmd"]).with_index(idx);
    let Some(results) = store.get_by_source(&amp;source) else {
        break;
    };
    // Process results...
    idx += 1;
}
<span class="boring">}</span></code></pre>
<p>This pattern handles any number of iterations without hardcoding the count.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="conditional-execution-2"><a class="header" href="#conditional-execution-2">Conditional Execution</a></h1>
<p><strong>Problem</strong>: You want certain commands to execute only when specific conditions are met at runtime.</p>
<p><strong>Solution</strong>: Use the <code>when</code> attribute with a Tera expression. If it evaluates to a falsy value, the command is skipped.</p>
<h2 id="how-the-when-attribute-works"><a class="header" href="#how-the-when-attribute-works">How the <code>when</code> Attribute Works</a></h2>
<p>Every command in Panopticon supports an optional <code>when</code> attribute:</p>
<ol>
<li>Before executing the command, the runtime evaluates the <code>when</code> expression</li>
<li>If the result is falsy (<code>false</code>, <code>null</code>, empty string, <code>0</code>), the command is skipped</li>
<li>Skipped commands have <code>status = "skipped"</code> in their metadata</li>
<li>Data results are absent for skipped commands</li>
</ol>
<h2 id="basic-pattern-feature-flags"><a class="header" href="#basic-pattern-feature-flags">Basic Pattern: Feature Flags</a></h2>
<p>The most common use case is feature-flagging parts of your pipeline.</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;

async fn run_with_feature_flag(enabled: bool) -&gt; anyhow::Result&lt;()&gt; {
    let mut pipeline = Pipeline::with_services(PipelineServices::defaults());

    // Static namespace with configuration
    pipeline
        .add_namespace(
            NamespaceBuilder::new("inputs")
                .static_ns()
                .insert("feature_enabled", ScalarValue::Bool(enabled))
                .insert("user_name", ScalarValue::String("Alice".to_string())),
        )
        .await?;

    // Command with `when` guard
    let attrs = ObjectBuilder::new()
        .insert("when", "inputs.feature_enabled")  // &lt;-- The condition
        .insert(
            "branches",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "greeting")
                    .insert("if", "true")
                    .insert("then", "Hello, {{ inputs.user_name }}! Feature is active.")
                    .build_scalar(),
            ]),
        )
        .insert("default", "Fallback message")
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("example"))
        .await?
        .add_command::&lt;ConditionCommand&gt;("greeting", &amp;attrs)
        .await?;

    // Execute
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;

    // Check the status
    let source = StorePath::from_segments(["example", "greeting"]);
    let cmd_results = results
        .get_by_source(&amp;source)
        .expect("Expected results");

    let status = cmd_results
        .meta_get(&amp;source.with_segment("status"))
        .expect("Expected status");

    println!("status = {}", status);

    // Data is only present when the command executed
    if let Some(result) = cmd_results
        .data_get(&amp;source.with_segment("result"))
        .and_then(|r| r.as_scalar())
    {
        println!("result = {}", result.1);
    } else {
        println!("(no data - command was skipped)");
    }

    Ok(())
}

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    println!("=== Feature flag: TRUE ===");
    run_with_feature_flag(true).await?;

    println!("\n=== Feature flag: FALSE ===");
    run_with_feature_flag(false).await?;

    Ok(())
}</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>=== Feature flag: TRUE ===
status = "completed"
result = Hello, Alice! Feature is active.

=== Feature flag: FALSE ===
status = "skipped"
(no data - command was skipped)
</code></pre>
<h2 id="tera-expression-syntax"><a class="header" href="#tera-expression-syntax">Tera Expression Syntax</a></h2>
<p>The <code>when</code> value is a Tera expression that has access to the entire scalar store. Common patterns:</p>
<h3 id="boolean-checks"><a class="header" href="#boolean-checks">Boolean Checks</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Direct boolean value
.insert("when", "config.debug_mode")

// Negation
.insert("when", "not config.production")

// Comparison
.insert("when", "config.log_level == \"debug\"")
<span class="boring">}</span></code></pre>
<h3 id="numeric-comparisons"><a class="header" href="#numeric-comparisons">Numeric Comparisons</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Greater than
.insert("when", "stats.row_count &gt; 0")

// Range check
.insert("when", "inputs.threshold &gt;= 10 and inputs.threshold &lt;= 100")
<span class="boring">}</span></code></pre>
<h3 id="string-tests"><a class="header" href="#string-tests">String Tests</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Equality
.insert("when", "config.environment == \"production\"")

// Prefix check
.insert("when", "region is starting_with(\"us-\")")

// Contains
.insert("when", "config.tags is containing(\"important\")")
<span class="boring">}</span></code></pre>
<h3 id="existence-checks"><a class="header" href="#existence-checks">Existence Checks</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Check if a value is defined
.insert("when", "optional_config is defined")

// Check for null
.insert("when", "maybe_value is not none")
<span class="boring">}</span></code></pre>
<h3 id="combined-conditions"><a class="header" href="#combined-conditions">Combined Conditions</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// AND
.insert("when", "config.enabled and stats.count &gt; 0")

// OR
.insert("when", "config.mode == \"full\" or config.force")

// Complex
.insert("when", "(env == \"prod\" or env == \"staging\") and feature_flags.new_flow")
<span class="boring">}</span></code></pre>
<h2 id="handling-skipped-commands"><a class="header" href="#handling-skipped-commands">Handling Skipped Commands</a></h2>
<p>When a command is skipped, you need to handle its absence in downstream commands.</p>
<h3 id="check-status-in-results"><a class="header" href="#check-status-in-results">Check Status in Results</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let status = cmd_results
    .meta_get(&amp;source.with_segment("status"))
    .expect("Expected status");

match status.as_str() {
    Some("completed") =&gt; {
        // Process data results
    }
    Some("skipped") =&gt; {
        // Handle skipped case
    }
    _ =&gt; {
        // Unexpected status
    }
}
<span class="boring">}</span></code></pre>
<h3 id="use-tera-defaults-in-templates"><a class="header" href="#use-tera-defaults-in-templates">Use Tera Defaults in Templates</a></h3>
<p>When referencing potentially-skipped command outputs in templates:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use default filter to handle missing values
.insert("message", "Count: {{ stats.count | default(value=0) }}")
<span class="boring">}</span></code></pre>
<h3 id="chain-conditions"><a class="header" href="#chain-conditions">Chain Conditions</a></h3>
<p>If command B depends on command A’s output, and A might be skipped:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Command A: might be skipped
let a_attrs = ObjectBuilder::new()
    .insert("when", "config.run_expensive_query")
    // ...
    .build_hashmap();

handle.add_command::&lt;SqlCommand&gt;("query_a", &amp;a_attrs).await?;

// Command B: only runs if A ran successfully
let b_attrs = ObjectBuilder::new()
    .insert("when", "ns.query_a.status == \"completed\"")
    // ...
    .build_hashmap();

handle.add_command::&lt;AggregateCommand&gt;("aggregate_b", &amp;b_attrs).await?;
<span class="boring">}</span></code></pre>
<h2 id="use-cases"><a class="header" href="#use-cases">Use Cases</a></h2>
<h3 id="debug-only-commands"><a class="header" href="#debug-only-commands">Debug-Only Commands</a></h3>
<p>Skip verbose logging in production:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.insert("when", "config.debug")
<span class="boring">}</span></code></pre>
<h3 id="empty-data-guards"><a class="header" href="#empty-data-guards">Empty Data Guards</a></h3>
<p>Skip processing when there is no data:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.insert("when", "data.load.rows &gt; 0")
<span class="boring">}</span></code></pre>
<h3 id="environment-specific-logic"><a class="header" href="#environment-specific-logic">Environment-Specific Logic</a></h3>
<p>Run different commands per environment:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Production-only
.insert("when", "config.env == \"production\"")

// Development-only
.insert("when", "config.env == \"development\"")
<span class="boring">}</span></code></pre>
<h3 id="conditional-exports"><a class="header" href="#conditional-exports">Conditional Exports</a></h3>
<p>Only export when there are results worth saving:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>.insert("when", "stats.significant_findings &gt; 0")
<span class="boring">}</span></code></pre>
<h3 id="iteration-guards"><a class="header" href="#iteration-guards">Iteration Guards</a></h3>
<p>Within an iterative namespace, skip certain items:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Skip disabled regions
.insert("when", "region is not starting_with(\"disabled-\")")

// Only process items meeting criteria
.insert("when", "item.status == \"active\"")
<span class="boring">}</span></code></pre>
<h2 id="best-practices-2"><a class="header" href="#best-practices-2">Best Practices</a></h2>
<h3 id="keep-conditions-simple"><a class="header" href="#keep-conditions-simple">Keep Conditions Simple</a></h3>
<p>Complex conditions are hard to debug. Prefer:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good: simple, readable
.insert("when", "config.feature_enabled")

// Avoid: complex nested logic
.insert("when", "((a and b) or (c and not d)) and (e or f)")
<span class="boring">}</span></code></pre>
<p>If you need complex logic, compute a boolean in an earlier command and reference it.</p>
<h3 id="document-skip-behavior"><a class="header" href="#document-skip-behavior">Document Skip Behavior</a></h3>
<p>When a command might be skipped, document what happens:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// This command is skipped when feature_x is disabled.
// Downstream commands that reference its output use default values.
let attrs = ObjectBuilder::new()
    .insert("when", "config.feature_x")
    // ...
<span class="boring">}</span></code></pre>
<h3 id="test-both-paths"><a class="header" href="#test-both-paths">Test Both Paths</a></h3>
<p>Always test your pipeline with conditions evaluating to both true and false to ensure proper handling.</p>
<h3 id="use-status-checks-for-dependencies"><a class="header" href="#use-status-checks-for-dependencies">Use Status Checks for Dependencies</a></h3>
<p>Instead of duplicating conditions, check the upstream command’s status:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Instead of repeating the condition:
// .insert("when", "config.feature_x")

// Check if the dependency actually ran:
.insert("when", "upstream.cmd.status == \"completed\"")
<span class="boring">}</span></code></pre>
<p>This ensures consistency even if the original condition logic changes.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="pipeline-editing-1"><a class="header" href="#pipeline-editing-1">Pipeline Editing</a></h1>
<p><strong>Problem</strong>: You have executed a pipeline and want to add more commands without re-running everything from scratch.</p>
<p><strong>Solution</strong>: Call <code>.edit()</code> on a completed pipeline to return to Draft state, add new namespaces and commands, then re-compile and execute.</p>
<h2 id="how-pipeline-editing-works"><a class="header" href="#how-pipeline-editing-works">How Pipeline Editing Works</a></h2>
<p>The Pipeline type has a state machine with three states:</p>
<pre><code>Draft  --compile--&gt;  Ready  --execute--&gt;  Completed
  ^                                           |
  |                                           |
  +------------------edit()-------------------+
</code></pre>
<p>When you call <code>.edit()</code> on a <code>Pipeline&lt;Completed&gt;</code>:</p>
<ol>
<li>The pipeline returns to <code>Pipeline&lt;Draft&gt;</code> state</li>
<li>All existing namespaces and commands are preserved</li>
<li>All data in the stores is preserved</li>
<li>You can add new namespaces and commands</li>
<li>Re-compilation and execution runs only the new additions (existing results remain)</li>
</ol>
<h2 id="basic-pattern-two-pass-pipeline"><a class="header" href="#basic-pattern-two-pass-pipeline">Basic Pattern: Two-Pass Pipeline</a></h2>
<p>A common workflow: load data, run initial analysis, review, then add more analysis.</p>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;
use std::path::PathBuf;

fn fixtures_dir() -&gt; PathBuf {
    PathBuf::from(env!("CARGO_MANIFEST_DIR")).join("fixtures")
}

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    // ===== Pass 1: Load data and run initial query =====
    println!("=== Pass 1: Load + Query ===\n");

    let mut pipeline = Pipeline::new();

    // Load users from CSV
    let file_attrs = ObjectBuilder::new()
        .insert(
            "files",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "users")
                    .insert("file", fixtures_dir().join("users.csv").to_string_lossy().to_string())
                    .insert("format", "csv")
                    .build_scalar(),
            ]),
        )
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("data"))
        .await?
        .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
        .await?;

    // Run a SQL query
    let sql_attrs = ObjectBuilder::new()
        .insert(
            "tables",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "users")
                    .insert("source", "data.load.users.data")
                    .build_scalar(),
            ]),
        )
        .insert("query", "SELECT name, age FROM users ORDER BY age DESC")
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("query"))
        .await?
        .add_command::&lt;SqlCommand&gt;("sorted", &amp;sql_attrs)
        .await?;

    // Execute pass 1
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;

    // Inspect pass 1 results
    let query_source = StorePath::from_segments(["query", "sorted"]);
    let query_results = results.get_by_source(&amp;query_source).expect("Expected query results");
    let rows = query_results.meta_get(&amp;query_source.with_segment("rows")).expect("Expected rows");
    println!("  query.sorted: {} rows", rows);
    println!("  Namespaces: data, query");

    // ===== Pass 2: Add aggregation to existing pipeline =====
    println!("\n=== Pass 2: Edit + Aggregate ===\n");

    // Return to Draft state - this is the key step!
    let mut pipeline = completed.edit();

    // Add aggregation namespace (data from pass 1 is still available)
    let agg_attrs = ObjectBuilder::new()
        .insert("source", "data.load.users.data")
        .insert(
            "aggregations",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "user_count")
                    .insert("op", "count")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "avg_age")
                    .insert("column", "age")
                    .insert("op", "mean")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "oldest")
                    .insert("column", "age")
                    .insert("op", "max")
                    .build_scalar(),
            ]),
        )
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("stats"))
        .await?
        .add_command::&lt;AggregateCommand&gt;("users", &amp;agg_attrs)
        .await?;

    // Re-compile and execute
    let completed = pipeline.compile().await?.execute().await?;
    let results = completed.results(ResultSettings::default()).await?;

    // Original results are still present
    let query_source = StorePath::from_segments(["query", "sorted"]);
    let query_results = results.get_by_source(&amp;query_source).expect("query.sorted should still exist");
    let rows = query_results.meta_get(&amp;query_source.with_segment("rows")).expect("Expected rows");
    println!("  query.sorted: {} rows (preserved from pass 1)", rows);

    // New aggregation results are available
    let stats_source = StorePath::from_segments(["stats", "users"]);
    let stats_results = results.get_by_source(&amp;stats_source).expect("Expected stats results");

    for name in ["user_count", "avg_age", "oldest"] {
        let value = stats_results
            .data_get(&amp;stats_source.with_segment(name))
            .and_then(|r| r.as_scalar())
            .expect(&amp;format!("Expected {}", name));
        println!("  stats.users.{} = {}", name, value.1);
    }

    println!("  Namespaces: data, query, stats");
    println!("\nPipeline successfully edited and re-executed.");

    Ok(())
}</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>=== Pass 1: Load + Query ===

  query.sorted: 5 rows
  Namespaces: data, query

=== Pass 2: Edit + Aggregate ===

  query.sorted: 5 rows (preserved from pass 1)
  stats.users.user_count = 5
  stats.users.avg_age = 32.4
  stats.users.oldest = 45
  Namespaces: data, query, stats

Pipeline successfully edited and re-executed.
</code></pre>
<h2 id="key-points"><a class="header" href="#key-points">Key Points</a></h2>
<h3 id="state-preservation"><a class="header" href="#state-preservation">State Preservation</a></h3>
<p>When you call <code>.edit()</code>:</p>
<ul>
<li><strong>Preserved</strong>: Namespaces, commands, store data, execution results</li>
<li><strong>Reset</strong>: Pipeline state returns to Draft</li>
</ul>
<p>This means pass 2 can reference data created in pass 1 without re-executing the original commands.</p>
<h3 id="ownership-transfer"><a class="header" href="#ownership-transfer">Ownership Transfer</a></h3>
<p>The <code>.edit()</code> method consumes the <code>Pipeline&lt;Completed&gt;</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// completed is consumed here
let mut pipeline = completed.edit();

// This would fail - completed no longer exists:
// let _ = completed.results(...);  // ERROR: use of moved value
<span class="boring">}</span></code></pre>
<h3 id="re-compilation-required"><a class="header" href="#re-compilation-required">Re-compilation Required</a></h3>
<p>After editing, you must call <code>.compile()</code> before <code>.execute()</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut pipeline = completed.edit();
pipeline.add_namespace(...).await?;

// Must compile before executing
let completed = pipeline.compile().await?.execute().await?;
<span class="boring">}</span></code></pre>
<h2 id="use-cases-1"><a class="header" href="#use-cases-1">Use Cases</a></h2>
<h3 id="exploratory-data-analysis"><a class="header" href="#exploratory-data-analysis">Exploratory Data Analysis</a></h3>
<p>Build your analysis incrementally:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Step 1: Load and explore
let completed = load_and_preview().await?;
// ... review results ...

// Step 2: Add filtering based on what you saw
let mut pipeline = completed.edit();
add_filters(&amp;mut pipeline).await?;
let completed = pipeline.compile().await?.execute().await?;
// ... review filtered results ...

// Step 3: Add aggregation
let mut pipeline = completed.edit();
add_aggregations(&amp;mut pipeline).await?;
let completed = pipeline.compile().await?.execute().await?;
<span class="boring">}</span></code></pre>
<h3 id="conditional-follow-up"><a class="header" href="#conditional-follow-up">Conditional Follow-Up</a></h3>
<p>Add analysis based on intermediate results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let completed = pipeline.compile().await?.execute().await?;
let results = completed.results(ResultSettings::default()).await?;

// Check if we need additional analysis
let row_count = get_row_count(&amp;results);
if row_count &gt; 1000 {
    let mut pipeline = completed.edit();
    add_sampling_namespace(&amp;mut pipeline).await?;
    let completed = pipeline.compile().await?.execute().await?;
}
<span class="boring">}</span></code></pre>
<h3 id="repl-style-workflows"><a class="header" href="#repl-style-workflows">REPL-Style Workflows</a></h3>
<p>In an interactive environment, let users add commands incrementally:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut completed = initial_pipeline.compile().await?.execute().await?;

loop {
    // Show current results
    display_results(&amp;completed).await?;

    // Get user input
    let command = get_user_command()?;
    if command == "quit" {
        break;
    }

    // Add the new command
    let mut pipeline = completed.edit();
    add_user_command(&amp;mut pipeline, &amp;command).await?;
    completed = pipeline.compile().await?.execute().await?;
}
<span class="boring">}</span></code></pre>
<h3 id="expensive-data-reuse"><a class="header" href="#expensive-data-reuse">Expensive Data Reuse</a></h3>
<p>Load expensive data once, analyze multiple ways:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Load large dataset (expensive)
let completed = load_big_dataset().await?;

// Analysis 1
let mut p1 = completed.edit();
add_analysis_1(&amp;mut p1).await?;
let c1 = p1.compile().await?.execute().await?;
save_results(&amp;c1, "analysis_1").await?;

// Analysis 2 (starts fresh from after load, not from c1)
let mut p2 = completed.edit();
add_analysis_2(&amp;mut p2).await?;
let c2 = p2.compile().await?.execute().await?;
save_results(&amp;c2, "analysis_2").await?;
<span class="boring">}</span></code></pre>
<p>Note: In this pattern, each <code>.edit()</code> call forks from the same point. Changes in <code>p1</code> do not affect <code>p2</code>.</p>
<h2 id="best-practices-3"><a class="header" href="#best-practices-3">Best Practices</a></h2>
<h3 id="name-namespaces-for-phases"><a class="header" href="#name-namespaces-for-phases">Name Namespaces for Phases</a></h3>
<p>Use namespace names that indicate which pass they belong to:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pass 1
.add_namespace(NamespaceBuilder::new("load"))
.add_namespace(NamespaceBuilder::new("initial_query"))

// Pass 2
.add_namespace(NamespaceBuilder::new("refined_query"))
.add_namespace(NamespaceBuilder::new("aggregations"))
<span class="boring">}</span></code></pre>
<h3 id="document-the-multi-pass-structure"><a class="header" href="#document-the-multi-pass-structure">Document the Multi-Pass Structure</a></h3>
<p>When your pipeline has multiple passes, document the intended flow:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pipeline structure:
// Pass 1: Load data, run initial validation
// Pass 2: Apply transformations based on validation results
// Pass 3: Generate final reports
<span class="boring">}</span></code></pre>
<h3 id="avoid-namespace-name-conflicts"><a class="header" href="#avoid-namespace-name-conflicts">Avoid Namespace Name Conflicts</a></h3>
<p>Each namespace must have a unique name. Adding a namespace with a duplicate name will fail:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Pass 1
pipeline.add_namespace(NamespaceBuilder::new("data")).await?;

// Pass 2 - this fails!
let mut pipeline = completed.edit();
pipeline.add_namespace(NamespaceBuilder::new("data")).await?;  // ERROR: duplicate name
<span class="boring">}</span></code></pre>
<h3 id="consider-memory-usage"><a class="header" href="#consider-memory-usage">Consider Memory Usage</a></h3>
<p>All store data is preserved across edits. For very large datasets, this can increase memory usage. If you need to release memory:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Create a fresh pipeline instead of editing
let mut new_pipeline = Pipeline::new();
// Copy only the data you need
<span class="boring">}</span></code></pre>
<h2 id="ready-state-editing"><a class="header" href="#ready-state-editing">Ready State Editing</a></h2>
<p>You can also call <code>.edit()</code> on a <code>Pipeline&lt;Ready&gt;</code> (after compile, before execute):</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let ready = pipeline.compile().await?;
// Oops, forgot something
let mut pipeline = ready.edit();
pipeline.add_namespace(...).await?;
let ready = pipeline.compile().await?;
let completed = ready.execute().await?;
<span class="boring">}</span></code></pre>
<p>This is useful when you realize you need to add something after compilation but before execution.</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="result-access-1"><a class="header" href="#result-access-1">Result Access</a></h1>
<p><strong>Problem</strong>: After pipeline execution, you need to retrieve results, export tabular data, and iterate over outputs programmatically.</p>
<p><strong>Solution</strong>: Use <code>ResultSettings</code> to configure output behavior and <code>ResultStore</code> to access and iterate over all command results.</p>
<h2 id="how-result-access-works"><a class="header" href="#how-result-access-works">How Result Access Works</a></h2>
<p>After calling <code>.execute()</code>, you have a <code>Pipeline&lt;Completed&gt;</code>. To access results:</p>
<ol>
<li>Create <code>ResultSettings</code> to configure output path and format</li>
<li>Call <code>.results(settings)</code> to get a <code>ResultStore</code></li>
<li>Use <code>ResultStore</code> methods to access individual command results</li>
<li>Each <code>CommandResults</code> contains metadata and data, accessible via iterators or direct lookup</li>
</ol>
<h2 id="basic-pattern-configure-and-collect"><a class="header" href="#basic-pattern-configure-and-collect">Basic Pattern: Configure and Collect</a></h2>
<pre class="playground"><code class="language-rust">use panopticon_core::prelude::*;
use std::path::PathBuf;

fn fixtures_dir() -&gt; PathBuf {
    PathBuf::from(env!("CARGO_MANIFEST_DIR")).join("fixtures")
}

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let output_dir = tempfile::tempdir()?;
    let mut pipeline = Pipeline::new();

    // Load product data
    let file_attrs = ObjectBuilder::new()
        .insert(
            "files",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "products")
                    .insert("file", fixtures_dir().join("products.csv").to_string_lossy().to_string())
                    .insert("format", "csv")
                    .build_scalar(),
            ]),
        )
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("data"))
        .await?
        .add_command::&lt;FileCommand&gt;("load", &amp;file_attrs)
        .await?;

    // Compute aggregations
    let agg_attrs = ObjectBuilder::new()
        .insert("source", "data.load.products.data")
        .insert(
            "aggregations",
            ScalarValue::Array(vec![
                ObjectBuilder::new()
                    .insert("name", "row_count")
                    .insert("op", "count")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "total_price")
                    .insert("column", "price")
                    .insert("op", "sum")
                    .build_scalar(),
                ObjectBuilder::new()
                    .insert("name", "avg_price")
                    .insert("column", "price")
                    .insert("op", "mean")
                    .build_scalar(),
            ]),
        )
        .build_hashmap();

    pipeline
        .add_namespace(NamespaceBuilder::new("stats"))
        .await?
        .add_command::&lt;AggregateCommand&gt;("products", &amp;agg_attrs)
        .await?;

    // Execute pipeline
    let completed = pipeline.compile().await?.execute().await?;

    // Configure result settings
    let settings = ResultSettings::new()
        .with_output_path(output_dir.path().to_path_buf())
        .with_format(TabularFormat::Json);

    // Collect results
    let results = completed.results(settings).await?;

    // Iterate over all results
    println!("=== Result Store ({} command(s)) ===\n", results.len());

    for cmd_results in results.iter() {
        println!("Source: {}", cmd_results.source().to_dotted());

        // Print metadata
        for (path, value) in cmd_results.meta_iter() {
            println!("  [meta] {} = {}", path.to_dotted(), value);
        }

        // Print data
        for (path, value) in cmd_results.data_iter() {
            match value.as_scalar() {
                Some((ty, val)) =&gt; {
                    println!("  [data] {} = {} ({:?})", path.to_dotted(), val, ty);
                }
                None =&gt; {
                    let (file_path, fmt, rows, cols) =
                        value.as_tabular().expect("Expected tabular result");
                    println!(
                        "  [data] {} =&gt; {} ({} rows x {} cols)",
                        path.to_dotted(),
                        file_path.display(),
                        rows,
                        cols
                    );
                }
            }
        }
        println!();
    }

    Ok(())
}</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>=== Result Store (2 command(s)) ===

Source: data.load
  [meta] data.load.products.rows = 10
  [meta] data.load.products.columns = ["name", "price", "quantity"]
  [data] data.load.products.data =&gt; /tmp/xxx/data_load_products.json (10 rows x 3 cols)

Source: stats.products
  [meta] stats.products.status = "completed"
  [data] stats.products.row_count = 10 (Int)
  [data] stats.products.total_price = 1250.50 (Float)
  [data] stats.products.avg_price = 125.05 (Float)
</code></pre>
<h2 id="resultsettings"><a class="header" href="#resultsettings">ResultSettings</a></h2>
<p><code>ResultSettings</code> configures how results are collected and exported.</p>
<h3 id="creating-settings"><a class="header" href="#creating-settings">Creating Settings</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Default settings
let settings = ResultSettings::default();

// Or use the builder
let settings = ResultSettings::new();
<span class="boring">}</span></code></pre>
<h3 id="output-path"><a class="header" href="#output-path">Output Path</a></h3>
<p>Specify where tabular data files are written:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let settings = ResultSettings::new()
    .with_output_path(PathBuf::from("/path/to/output"));
<span class="boring">}</span></code></pre>
<p>Default: <code>./panopticon_results</code> in the current working directory.</p>
<h3 id="output-format"><a class="header" href="#output-format">Output Format</a></h3>
<p>Choose the format for tabular data exports:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// JSON (default)
let settings = ResultSettings::new()
    .with_format(TabularFormat::Json);

// CSV
let settings = ResultSettings::new()
    .with_format(TabularFormat::Csv);

// Parquet (efficient binary format)
let settings = ResultSettings::new()
    .with_format(TabularFormat::Parquet);
<span class="boring">}</span></code></pre>
<h3 id="excluded-commands"><a class="header" href="#excluded-commands">Excluded Commands</a></h3>
<p>Skip specific commands when collecting results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let settings = ResultSettings::new()
    .with_excluded_commands(vec![
        StorePath::from_segments(["debug", "verbose_log"]),
        StorePath::from_segments(["temp", "intermediate"]),
    ]);
<span class="boring">}</span></code></pre>
<p>Excluded commands do not appear in the <code>ResultStore</code> and their tabular data is not exported.</p>
<h2 id="resultstore"><a class="header" href="#resultstore">ResultStore</a></h2>
<p>The <code>ResultStore</code> contains all command results from the pipeline execution.</p>
<h3 id="basic-access"><a class="header" href="#basic-access">Basic Access</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let results = completed.results(settings).await?;

// Number of commands with results
let count = results.len();

// Check if empty
if results.is_empty() {
    println!("No results");
}
<span class="boring">}</span></code></pre>
<h3 id="lookup-by-source"><a class="header" href="#lookup-by-source">Lookup by Source</a></h3>
<p>Access a specific command’s results by its store path:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let source = StorePath::from_segments(["namespace", "command"]);

if let Some(cmd_results) = results.get_by_source(&amp;source) {
    // Process this command's results
}
<span class="boring">}</span></code></pre>
<h3 id="iteration-2"><a class="header" href="#iteration-2">Iteration</a></h3>
<p>Iterate over all command results:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>for cmd_results in results.iter() {
    println!("Command: {}", cmd_results.source().to_dotted());
}
<span class="boring">}</span></code></pre>
<h2 id="commandresults"><a class="header" href="#commandresults">CommandResults</a></h2>
<p>Each <code>CommandResults</code> contains the outputs from a single command.</p>
<h3 id="source-path"><a class="header" href="#source-path">Source Path</a></h3>
<p>The path identifying this command:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let source: &amp;StorePath = cmd_results.source();
println!("Command at: {}", source.to_dotted());
<span class="boring">}</span></code></pre>
<h3 id="metadata-access"><a class="header" href="#metadata-access">Metadata Access</a></h3>
<p>Metadata includes execution information like row counts, column names, and status:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Direct lookup
let source = StorePath::from_segments(["data", "load"]);
let rows = cmd_results
    .meta_get(&amp;source.with_segment("products").with_segment("rows"))
    .expect("Expected rows");

// Iterate all metadata
for (path, value) in cmd_results.meta_iter() {
    println!("{} = {}", path.to_dotted(), value);
}

// Get all metadata keys
for key in cmd_results.meta_keys() {
    println!("Meta key: {}", key.to_dotted());
}
<span class="boring">}</span></code></pre>
<h3 id="data-access"><a class="header" href="#data-access">Data Access</a></h3>
<p>Data includes the actual outputs (scalar values or tabular data references):</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Direct lookup
let source = StorePath::from_segments(["stats", "products"]);
let avg = cmd_results
    .data_get(&amp;source.with_segment("avg_price"))
    .and_then(|r| r.as_scalar());

// Iterate all data
for (path, value) in cmd_results.data_iter() {
    match value.as_scalar() {
        Some((ty, val)) =&gt; println!("Scalar: {} = {}", path.to_dotted(), val),
        None =&gt; {
            let (file, fmt, rows, cols) = value.as_tabular().unwrap();
            println!("Tabular: {} -&gt; {}", path.to_dotted(), file.display());
        }
    }
}

// Get all data keys
for key in cmd_results.data_keys() {
    println!("Data key: {}", key.to_dotted());
}
<span class="boring">}</span></code></pre>
<h2 id="resultvalue"><a class="header" href="#resultvalue">ResultValue</a></h2>
<p>Each data value is either scalar or tabular.</p>
<h3 id="scalar-values"><a class="header" href="#scalar-values">Scalar Values</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if let Some((ty, value)) = result_value.as_scalar() {
    // ty: &amp;ScalarType (Int, Float, String, Bool, etc.)
    // value: &amp;ScalarValue
    println!("Type: {:?}, Value: {}", ty, value);
}

// Type check
if result_value.is_scalar() {
    // ...
}
<span class="boring">}</span></code></pre>
<h3 id="tabular-values"><a class="header" href="#tabular-values">Tabular Values</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if let Some((path, format, rows, cols)) = result_value.as_tabular() {
    // path: &amp;PathBuf - file location on disk
    // format: &amp;TabularFormat - Csv, Json, or Parquet
    // rows: usize - row count
    // cols: usize - column count
    println!("File: {}, Format: {}, Shape: {}x{}",
             path.display(), format, rows, cols);
}

// Type check
if result_value.is_tabular() {
    // ...
}
<span class="boring">}</span></code></pre>
<h2 id="patterns-for-common-tasks"><a class="header" href="#patterns-for-common-tasks">Patterns for Common Tasks</a></h2>
<h3 id="print-summary-report"><a class="header" href="#print-summary-report">Print Summary Report</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>println!("Pipeline Results Summary");
println!("========================");

for cmd_results in results.iter() {
    let source = cmd_results.source();
    print!("{}: ", source.to_dotted());

    // Check status
    if let Some(status) = cmd_results.meta_get(&amp;source.with_segment("status")) {
        if status.as_str() == Some("skipped") {
            println!("SKIPPED");
            continue;
        }
    }

    // Count outputs
    let scalar_count = cmd_results.data_iter()
        .filter(|(_, v)| v.is_scalar())
        .count();
    let tabular_count = cmd_results.data_iter()
        .filter(|(_, v)| v.is_tabular())
        .count();

    println!("{} scalars, {} tables", scalar_count, tabular_count);
}
<span class="boring">}</span></code></pre>
<h3 id="export-all-tables-to-directory"><a class="header" href="#export-all-tables-to-directory">Export All Tables to Directory</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let settings = ResultSettings::new()
    .with_output_path(export_dir.to_path_buf())
    .with_format(TabularFormat::Parquet);

let results = completed.results(settings).await?;

// List exported files
println!("Exported files:");
for entry in std::fs::read_dir(&amp;export_dir)? {
    let entry = entry?;
    let meta = entry.metadata()?;
    println!("  {} ({} bytes)",
             entry.file_name().to_string_lossy(),
             meta.len());
}
<span class="boring">}</span></code></pre>
<h3 id="collect-scalar-metrics"><a class="header" href="#collect-scalar-metrics">Collect Scalar Metrics</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut metrics: HashMap&lt;String, f64&gt; = HashMap::new();

for cmd_results in results.iter() {
    for (path, value) in cmd_results.data_iter() {
        if let Some((ScalarType::Float, scalar)) = value.as_scalar() {
            if let Some(f) = scalar.as_f64() {
                metrics.insert(path.to_dotted(), f);
            }
        }
    }
}

for (name, value) in &amp;metrics {
    println!("{}: {:.2}", name, value);
}
<span class="boring">}</span></code></pre>
<h3 id="handle-iterative-results"><a class="header" href="#handle-iterative-results">Handle Iterative Results</a></h3>
<p>For iterative namespaces, results are indexed:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut iteration = 0;
loop {
    let source = StorePath::from_segments(["iterative_ns", "command"])
        .with_index(iteration);

    let Some(cmd_results) = results.get_by_source(&amp;source) else {
        break; // No more iterations
    };

    println!("Iteration {}: {:?}", iteration, cmd_results.source().to_dotted());

    // Process this iteration's results...

    iteration += 1;
}

println!("Total iterations: {}", iteration);
<span class="boring">}</span></code></pre>
<h2 id="best-practices-4"><a class="header" href="#best-practices-4">Best Practices</a></h2>
<h3 id="choose-the-right-format"><a class="header" href="#choose-the-right-format">Choose the Right Format</a></h3>
<ul>
<li><strong>JSON</strong>: Human-readable, good for debugging and small datasets</li>
<li><strong>CSV</strong>: Widely compatible, good for sharing with other tools</li>
<li><strong>Parquet</strong>: Efficient storage, good for large datasets and further processing</li>
</ul>
<h3 id="clean-up-output-directories"><a class="header" href="#clean-up-output-directories">Clean Up Output Directories</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Use tempdir for automatic cleanup
let output_dir = tempfile::tempdir()?;
let settings = ResultSettings::new()
    .with_output_path(output_dir.path().to_path_buf());

// output_dir is deleted when it goes out of scope
<span class="boring">}</span></code></pre>
<h3 id="handle-missing-results-gracefully"><a class="header" href="#handle-missing-results-gracefully">Handle Missing Results Gracefully</a></h3>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let source = StorePath::from_segments(["maybe", "exists"]);

match results.get_by_source(&amp;source) {
    Some(cmd_results) =&gt; {
        // Process results
    }
    None =&gt; {
        println!("Command {} not in results (possibly excluded or skipped)",
                 source.to_dotted());
    }
}
<span class="boring">}</span></code></pre>
<h3 id="use-type-safe-path-construction"><a class="header" href="#use-type-safe-path-construction">Use Type-Safe Path Construction</a></h3>
<p>Build paths systematically to avoid typos:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Define base paths once
let stats_base = StorePath::from_segments(["stats", "products"]);

// Build specific paths from the base
let row_count = stats_base.with_segment("row_count");
let avg_price = stats_base.with_segment("avg_price");
let total = stats_base.with_segment("total_price");
<span class="boring">}</span></code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="services--io"><a class="header" href="#services--io">Services &amp; IO</a></h1>
<p>Panopticon pipelines can interact with the outside world through <strong>services</strong>. The <code>PipelineServices</code> struct bundles two categories of functionality:</p>
<ul>
<li><strong>PipelineIO</strong> - Send notifications and prompt for user input</li>
<li><strong>EventHooks</strong> - React to pipeline lifecycle events (compilation, execution, completion)</li>
</ul>
<p>Services are optional. A pipeline without services runs silently, which is often what you want for batch processing or automated workflows. When you need feedback or interactivity, services provide a clean abstraction.</p>
<h2 id="attaching-services-to-a-pipeline"><a class="header" href="#attaching-services-to-a-pipeline">Attaching Services to a Pipeline</a></h2>
<p>Use <code>Pipeline::with_services()</code> to attach a <code>PipelineServices</code> instance:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use panopticon_core::prelude::*;

let services = PipelineServices::defaults();
let mut pipeline = Pipeline::with_services(services);
<span class="boring">}</span></code></pre>
<h2 id="using-pipelineio"><a class="header" href="#using-pipelineio">Using PipelineIO</a></h2>
<p>The <code>PipelineIO</code> trait provides two methods for interacting with users:</p>
<ul>
<li><code>notify(message)</code> - Display a message (fire-and-forget)</li>
<li><code>prompt(message)</code> - Display a message and wait for a response</li>
</ul>
<p>Commands access these through the <code>ExecutionContext</code>:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Inside a command's execute method
ctx.services().notify("Processing started...").await?;

if let Some(answer) = ctx.services().prompt("Continue? (y/n)").await? {
    if answer.to_lowercase() == "y" {
        // proceed
    }
}
<span class="boring">}</span></code></pre>
<p>Multiple IO services can be registered. When you call <code>notify</code>, all registered services receive the message. When you call <code>prompt</code>, services are tried in order until one returns a response.</p>
<h2 id="event-hooks"><a class="header" href="#event-hooks">Event Hooks</a></h2>
<p>Event hooks let you observe pipeline lifecycle events without modifying command logic. Hooks fire at key moments:</p>
<ul>
<li><strong>Draft phase</strong>: After namespaces/commands are added, before/after compilation</li>
<li><strong>Ready phase</strong>: Before/after pipeline, namespace, and command execution</li>
<li><strong>Completed phase</strong>: When results are being collected</li>
</ul>
<p>This is useful for logging, metrics, progress reporting, or custom debugging.</p>
<h2 id="default-services"><a class="header" href="#default-services">Default Services</a></h2>
<p><code>PipelineServices::defaults()</code> behaves differently based on build mode:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Build Mode</th><th>IO Service</th><th>Event Hooks</th></tr>
</thead>
<tbody>
<tr><td>Debug (<code>cfg(debug_assertions)</code>)</td><td><code>StdoutInteraction</code></td><td><code>DebugEventHooks</code></td></tr>
<tr><td>Release</td><td>None</td><td>None</td></tr>
</tbody>
</table>
</div>
<p>In debug builds, you get console output and lifecycle logging out of the box. In release builds, services start empty for maximum control.</p>
<p>To start with no services regardless of build mode:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let services = PipelineServices::new();
<span class="boring">}</span></code></pre>
<h2 id="implementing-custom-services"><a class="header" href="#implementing-custom-services">Implementing Custom Services</a></h2>
<p>This guide covers <em>using</em> services. For implementing your own <code>PipelineIO</code> or <code>EventHooks</code>:</p>
<p><strong><a href="../extending/src/services/index.html">See the Extend guide: Implementing Services</a></strong></p>
<p>The Extend guide covers:</p>
<ul>
<li>Implementing the <code>PipelineIO</code> trait for custom notification channels</li>
<li>Implementing <code>EventHooks</code> for lifecycle callbacks</li>
<li>Available hook events and their payloads</li>
<li>Registering multiple services with <code>add_io()</code> and <code>add_hook()</code></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
